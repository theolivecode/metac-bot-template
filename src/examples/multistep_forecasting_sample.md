2025-12-21 15:48:09,440 - root - INFO - Logging configured: level=INFO, log_to_file=False
2025-12-21 15:48:09,440 - __main__ - INFO - ============================================================
2025-12-21 15:48:09,440 - __main__ - INFO - Metaculus Forecasting Bot - Refactored Version
2025-12-21 15:48:09,440 - __main__ - INFO - ============================================================
2025-12-21 15:48:09,477 - __main__ - INFO - Using LLM research provider
2025-12-21 15:48:09,478 - __main__ - INFO - Using example questions
2025-12-21 15:48:09,478 - __main__ - INFO - ============================================================
2025-12-21 15:48:09,478 - __main__ - INFO - Questions to forecast: [(578, 578)]
2025-12-21 15:48:09,478 - __main__ - INFO - Submit predictions: False
2025-12-21 15:48:09,478 - __main__ - INFO - Runs per question: 3
2025-12-21 15:48:09,478 - __main__ - INFO - Skip previously forecasted: False
2025-12-21 15:48:09,478 - __main__ - INFO - ============================================================
2025-12-21 15:48:09,478 - __main__ - INFO - Starting forecast for 1 questions
2025-12-21 15:48:09,478 - __main__ - INFO - ============================================================
2025-12-21 15:48:09,478 - __main__ - INFO - Forecasting Question 578 (Post 578)
2025-12-21 15:48:09,478 - __main__ - INFO - ============================================================
2025-12-21 15:48:09,478 - src.api.metaculus_client - INFO - Getting details for post 578
2025-12-21 15:48:10,285 - __main__ - INFO - Title: Will humans go extinct before 2100?
2025-12-21 15:48:10,285 - __main__ - INFO - Type: binary
2025-12-21 15:48:10,285 - __main__ - INFO - Resolution Criteria: This question will resolve as **Yes** if there are no known humans alive on January 1, 2100.  For these purposes we'll define humans as biological creatures who have as their ancestors – via a chain of live births from mothers –  circa 2000 humans OR who could mate with circa 2000 humans to produce viable offspring. (So AIs, ems, genetically engineered beings of a different species brought up in artificial wombs, etc. would not count).  Any living humans living anywhere in the observable universe (or multiverse) (who are known to the entities operating Metaculus) on that date will be sufficient to resolve the question negatively.

N.B. Even though it is obviously the case that if human extinction occurs Metaculus points won't be very valuable anymore and that it will be practically impossible to check for true human extinction (zero humans left), I would like to ask people not to let this fact influence their prediction and to predict in good faith
2025-12-21 15:48:10,285 - __main__ - INFO - Fine Print: 
2025-12-21 15:48:10,286 - src.forecasting.binary - INFO - Starting binary forecast with 3 runs
2025-12-21 15:48:10,286 - src.research.llm - INFO - ====================
2025-12-21 15:48:10,286 - src.research.llm - INFO - Running Multi-Step Research with LLM...
2025-12-21 15:48:10,286 - src.research.llm - INFO - Model: openai/o4-mini-deep-research
2025-12-21 15:48:10,286 - src.research.llm - INFO - Research Question: 'Will humans go extinct before 2100?'
2025-12-21 15:48:10,286 - src.research.llm - INFO - ====================
2025-12-21 15:48:10,286 - src.research.llm - INFO - 
[Step 1/5] Classifying question into field...
2025-12-21 15:48:10,286 - src.utils.llm_client - INFO - Calling API LLM with model=openai/o4-mini-deep-research, temperature=0.7
2025-12-21 15:48:26,133 - src.research.llm - INFO - Field Classification:
Field: Science  
Sub-field: Existential Risk / Futurology  

Reasoning: The question concerns the future survival of humanity, a topic studied in scientific fields like ecology, climate science, and global risk analysis (often called existential or catastrophic risk).
2025-12-21 15:48:26,134 - src.research.llm - INFO - 
[Step 2/5] Searching for related entities and countries...
2025-12-21 15:48:26,134 - src.utils.llm_client - INFO - Calling API LLM with model=openai/o4-mini-deep-research, temperature=0.7
2025-12-21 15:50:31,242 - src.research.llm - INFO - Entities Found:
Entities:
- United Nations (UN)  
- Intergovernmental Panel on Climate Change (IPCC)  
- World Health Organization (WHO)  
- International Atomic Energy Agency (IAEA)  
- Paris Climate Agreement  
- Nuclear Non-Proliferation Treaty (NPT)  
- OpenAI (AI research company)  
- Google DeepMind (AI research lab)  
- Elon Musk (technology entrepreneur, AI and space ventures)  
- Bill Gates (technologist and philanthropist focused on global risks)  
- Future of Humanity Institute (Oxford University research center)  
- Centre for the Study of Existential Risk (Cambridge University research group)  

Countries/Regions:
- United States  
- China  
- Russia  
- European Union  
- India  

Reasoning: This question touches on existential risks from climate change, nuclear war, pandemics, artificial intelligence, and other global threats. International organizations like the UN, IPCC, WHO, and IAEA coordinate science and policy on climate, health, and nuclear issues. Major treaties (the Paris Agreement on climate, the Nuclear Non-Proliferation Treaty) set binding goals to avoid worst-case scenarios. Leading AI companies (OpenAI, DeepMind) and tech figures (Elon Musk, Bill Gates) are prominent voices on how advanced AI or biotechnology might pose extinction risks. Research institutes such as Oxford’s Future of Humanity Institute and Cambridge’s Centre for the Study of Existential Risk specifically study long-term human survival. The listed countries and regions (e.g., U.S., China, Russia, EU, India) are the largest emitters of greenhouse gases, nuclear powers, or centers of technological development; their policies and actions have an outsized influence on whether climate breakdown, nuclear conflict, deadly pandemics, or runaway AI emerge as existential threats before 2100.
2025-12-21 15:50:31,244 - src.research.llm - INFO - 
[Step 3/5] Analyzing entity characteristics and relationships...
2025-12-21 15:50:31,244 - src.utils.llm_client - INFO - Calling API LLM with model=openai/o4-mini-deep-research, temperature=0.7
2025-12-21 15:57:35,655 - src.research.llm - INFO - Entity Analysis:
## United Nations (UN)  
- **Institutional approach/character:** The UN is a broad, consensus‐driven multilateral organization whose character is bureaucratic and diplomatic.  It embodies a global consensus ethos – aiming for “unprecedented systemic change” on climate, health and security as a collective problem ([apnews.com](https://apnews.com/article/584715f6fd7ed32a8cf993120ef2a8aa#:~:text=pollution%2C%20biodiversity%20loss%2C%20and%20land,roughly%209%20million%20deaths%20annually)) – but is often slow-moving due to its large and diverse membership.  The UN typically emphasizes integrated, science-backed approaches to existential threats (e.g. its environment assembly recently linked climate, pollution and biodiversity as interconnected crises requiring coordinated action ([apnews.com](https://apnews.com/article/584715f6fd7ed32a8cf993120ef2a8aa#:~:text=pollution%2C%20biodiversity%20loss%2C%20and%20land,roughly%209%20million%20deaths%20annually))).  
- **Typical approach to tasks:** The UN coordinates international treaties and summits but has no enforcement power.  It relies on agencies (like UNFCCC for climate, WHO for health, IAEA for nuclear) to set norms and mobilize member states.  In practice it uses proclamations, multilateral frameworks (e.g. Sustainable Development Goals) and peacekeeping, but outcomes hinge on member consensus.  The UN’s history shows it brokered landmark accords (NPT, Paris, health regulations) yet often struggles to translate those into concrete action without buy-in from great powers.  
- **Relationships with other entities:** The UN formally hosts or works with many listed entities (IPCC, WHO, IAEA are UN bodies or affiliates).  It links to the Paris Agreement and NPT through its UNFCCC and disarmament offices.  Its member countries include the U.S., China, Russia, EU and India, which can block or advance UN efforts (e.g. U.S. withdrawal from Paris under Trump weakened UN climate cohesion ([apnews.com](https://apnews.com/article/788907bb89fe307a964be757313cdfb0#:~:text=On%20January%2020%2C%202025%2C%20shortly,to%20climate%20and%20energy%20policy))).  The UN also interacts with private voices (Gates, Musk) in dialogue forums on global risks.  Overall, it sits at the center of this network: encouraging cooperation (climate summits, health assemblies) while navigating geopolitical tensions.  
- **Current motivations/incentives:** The UN’s institutional mission is to preserve peace, security, and human development (e.g. SDGs), so it is motivated to avert existential threats like climate catastrophe, pandemics and nuclear war.  It is incentivized politically by member states’ concerns and crises; for example, seeing emissions surge, UN agencies now stress urgency (“time is running out to ensure a thriving human society” ([apnews.com](https://apnews.com/article/584715f6fd7ed32a8cf993120ef2a8aa#:~:text=particularly%20with%20the%20U,thriving%20human%20society%20on%20Earth))).  However, as a consensus body the UN’s incentives are also to maintain member engagement rather than impose solutions.  It often reframes short-term aid (health, development) as building resilience against long-term risk.  
- **Historical patterns of behavior:** Historically, the UN has been effective at framing global problems (e.g. issuing warnings on climate or pandemics) and building near-universal coalitions (e.g. almost all countries signing the Paris pact or NPT).  It has a pattern of gradual norm-setting: for decades it promoted nuclear non-proliferation and climate targets.  However, many critiques note also its limitations: great-power vetoes, enforcement gaps, and a tendency to produce broad resolutions rather than swift action.  Historically, it has avoided direct confrontation but will publicly highlight existential dangers (e.g. past Secretary-Generals have called nuclear war and climate change “existential threats”).  In summary, expect the UN to continue championing global cooperation and issuing scientific reports, but actual impact on prevention depends on its members’ political will.  

## Intergovernmental Panel on Climate Change (IPCC)  
- **Institutional approach/character:** The IPCC is a UN-sponsored scientific body whose character is highly academic, evidence-driven and consensus-oriented.  It does not make policy but synthesizes climate science for governments, always under the guiding motto “policy-relevant but not policy-prescriptive.”  In essence, it is very cautious and conservative in language (since it requires unanimity among dozens of countries); its reports build on thousands of peer-reviewed studies to give the clearest picture of climate risk.  In effect, it is “an international equivalent to national committees” on climate science ([www.nature.com](https://www.nature.com/articles/s44168-023-00094-x#:~:text=The%20IPCC%20was%20set%20up,climate%20change%20and%20its%20effects)) – a vehicle for international consensus on what science says.  
- **Typical approach to tasks:** The IPCC’s work pattern is methodical: it organizes large assessment reports roughly every 5–8 years, working with hundreds of scientists and multiple rounds of review.  It lays out projections (emissions trajectories, temperature scenarios) and “key risks,” but it does not propose policies or enforce anything.  Its approach is to present ranges of outcomes, uncertainties, and let political bodies (like the UN climate talks) draw conclusions.  Because of this, the IPCC often understates worst-case (low-probability) extremes due to the need for unanimous agreement.  Still, it has a track record of increasingly urgent warnings: each assessment has gotten progressively firmer that unchecked emissions lead to severe global consequences (from AR1’s early warnings to AR6’s unequivocal link between human activity and warming).  
- **Relationships with other entities:** The IPCC interacts closely with the UNFCCC and Paris Agreement, serving as the primary scientific input for policy discussions.  Its reports inform UN agencies (like UNEP) and national governments (the US, China, EU all rely on IPCC findings in diplomacy).  It has ties to academic institutes (many IPCC authors hail from universities) and sometimes to research hubs like FHI or CSER that specialize in climate risk.  The IPCC does not have a direct relationship with private companies (OpenAI, Musk, etc), but its science underpins broad debates those actors have on long-term risk.  In effect, IPCC findings shape the broader climate narrative that all players respond to.  
- **Current motivations/incentives:** The IPCC’s motivation is to maintain scientific credibility and accuracy.  It is incentivized by the UN member governments’ demand for reliable data but balances this with a need to not alarm or mislead.  Internally, IPCC working groups seek to reflect the most recent evidence; externally, countries push to soften or highlight sections relevant to them (for example, some oil-exporting states have historically lobbied to soften messages).  Militarily, it has no stake, but its incentive is to keep climate change on the agenda – indeed, it has helped frame climate change as a global security issue.  
- **Historical patterns of behavior:** Over time, the IPCC has built trust for reliability and incremental updates.  Historically it has been slower to highlight low-probability but catastrophic risks – a known criticism.  It adapts gradually: for example starting from stating that “climate change is happening” to now warning of surpassing 2°C without drastic cuts.  The IPCC has occasionally been accused of being too conservative (e.g. underplaying Arctic ice melt), but its general pattern has been to ramp up urgency as evidence solidifies.  An analyst notes the IPCC itself is a “triumph of international cooperation… building consensus and evolving in response to evidence” ([www.nature.com](https://www.nature.com/articles/s44168-023-00094-x#:~:text=The%20IPCC%20was%20set%20up,climate%20change%20and%20its%20effects)).  In a forecast context, one can expect IPCC to continue that trend: presenting worrisome projections to galvanize policy, but always with cautious framing.

## World Health Organization (WHO)  
- **Institutional approach/character:** The WHO is a UN agency with a public-health mandate.  It approaches global health threats through developing guidelines, planning frameworks and coordinating international responses.  Its character is administrative and expert-driven, relying on a network of health and research institutions.  The WHO is typically non-coercive: it advises rather than orders, and stands by doctrines like the International Health Regulations, which require countries to report outbreaks and build capacity.  It has a top-heavy leadership (the DG and member-state executive board) but works primarily through regional offices and partnerships.  
- **Typical approach to tasks:** Historically, WHO leads campaigns (e.g. smallpox eradication) and issues guidance (vaccination schedules, pandemic preparedness).  It provides technical support, mobilizes funding for health emergencies, and convenes member states to coordinate (e.g. Global Health Security Agenda).  In pandemics, the WHO typically tries to gather data, produce standards (case definitions, travel advisories) and monitor compliance; it famously declared Public Health Emergencies when necessary.  During COVID-19, WHO launched initiatives like the COVID-19 Solidarity Response Fund and later evaluated lessons learned.  Generally, it’s reactive – it ramps up when crises occur, then pushes for stronger systems afterwards.  
- **Relationships with other entities:** The WHO works closely with UN bodies (e.g. collaborating on SDG3 for health).  It coordinates with governments and NGOs (e.g. UNICEF, Gates Foundation) which fund much of its budget.  Notably, Bill Gates’s foundation is a top donor and partner on issues like vaccine delivery.  It interacts with research groups (for instance, it involves epidemiologists and labs globally) and with regulatory agencies (FDA, EMA) for health matters.  In the current context, WHO’s frameworks (like the Framework for Pandemic Prevention) intersect with existential-risk centers (FHI, CSER) when addressing biosecurity.  WHO also liaises with countries’ militaries or disaster agencies during crises.  Tensions sometimes arise with states (e.g. accusations during COVID-19) but WHO generally stays apolitical.  
- **Current motivations/incentives:** The WHO is motivated by its constitutional mandate to achieve global health and well-being.  It is financially incentivized by donor priorities and member state politics, meaning attention often follows what crises get funding (pandemics, yes; chronic diseases, some).  After the COVID-19 pandemic, the WHO has been pushing stronger health security frameworks (for example, a new “global framework for understanding the origins of novel pathogens” was launched in 2024 ([www.who.int](https://www.who.int/news/item/04-09-2024-who-launches-global-framework-for-understanding-the-origins-of-new-or-re-emerging-pathogens#:~:text=Ghebreyesus%2C%20WHO%20Director,have%20been%20less%20contentious%20and)) to standardize outbreak investigation).  Its incentive now is to build on that momentum: demonstrating that WHO-derived guidance (rather than silence or politics) leads to better outcomes.  It is also under pressure to reform governance, so it seeks to show proactive leadership to retain relevance.  
- **Historical patterns of behavior:** Historically, WHO has alternated between high-impact successes (smallpox, polio efforts) and criticism for slow response (e.g. 2014 Ebola delays, COVID-19 controversies).  It tends toward conservatism in declaring emergencies (it was slow to declare COVID-19 a PHEIC, then came under fire).  After crises, it often proposes new international mechanisms (like the IHR) to fix gaps.  WHO committees (e.g. the World Health Assembly) meet annually but can be outmaneuvered by geopolitics.  Overall, WHO’s pattern is “learning by doing” – it issues guidance on best practices (like the new origin-tracing framework ([www.who.int](https://www.who.int/news/item/04-09-2024-who-launches-global-framework-for-understanding-the-origins-of-new-or-re-emerging-pathogens#:~:text=Ghebreyesus%2C%20WHO%20Director,have%20been%20less%20contentious%20and))) and tries to get consensus for stronger action, but relies on member states to follow through.  In forecasting, one would expect WHO to emphasize preparedness, support vaccine R&D, and continue pushing global surveillance networks – but it will still be limited by politics and funding.  

## International Atomic Energy Agency (IAEA)  
- **Institutional approach/character:** The IAEA is an independent international organization (though affiliated with the UN) that serves as the global watchdog and promoter of nuclear technology.  Its character is technical and regulatory: it conducts inspections and monitors nuclear facilities to ensure compliance with safeguards.  The IAEA also promotes peaceful uses of nuclear energy (for electricity, medicine, etc.) under its dual mission.  It is led by a Director General and reporting to a Board of Governors, but policy directives ultimately come from member states (with influence from the Security Council, especially on non-proliferation).  
- **Typical approach to tasks:** The IAEA’s usual work is systematic inspections: it verifies that signatories to the NPT use nuclear material only for peaceful purposes by accounting for reactors and labs.  It also provides technical assistance for nuclear safety and radiation protection.  In crisis scenarios (suspected illicit weapons programs), the IAEA investigates and reports facts (as with Iran or North Korea).  It convenes conferences on nuclear security and encourages countries to adopt additional protocols for transparency.  The IAEA’s reports (e.g. safeguards reports) typically inform diplomatic negotiations.  On nuclear disasters (Chernobyl, Fukushima), it provides expertise on containment and health effects.  
- **Relationships with other entities:** The IAEA is tightly linked to the NPT (all NPT signatories are subject to safeguards) and works with UN bodies like the Security Council (to enforce non-compliance through sanctions) and the General Assembly (for technical support).  It collaborates with nuclear-armed states (US, Russia, China, EU members with reactors like France) to implement checks, but those states often negotiate exemptions or extended cameras.  It addresses concerns brought by NGOs or research institutes (like findings of clandestine labs).  In existential-risk terms, the IAEA bridges with WHO in nuclear accident response and with climate bodies when discussing nuclear energy as a low-carbon source.  Its relationship with AI actors (OpenAI, Musk) is minimal, except that some experts inside IAEA are aware of the cyber risk to nuclear plants, which intersects with AI weaponization concerns.  
- **Current motivations/incentives:** The IAEA is motivated by its mission to prevent nuclear proliferation while promoting peaceful nuclear use.  It is incentivized to maintain credibility as an impartial verifier (so its non-compliance reports must be accurate).  Politically, it must balance between pushing strict access (to catch cheating) and keeping members on board (excessive inspections might drive states away).  In recent years, it has emphasized nuclear safety more strongly (e.g. after Fukushima) and supports nuclear power as part of climate solutions, giving it an incentive to avoid alarmist tones.  However, it also faces pressure from major powers: for example, Russia and China have in the past limited IAEA’s reach in places like DPRK or Iran, affecting its incentives to stand firm or compromise.  
- **Historical patterns of behavior:** Historically, the IAEA has mostly succeeded in verifying the NPT system (the broad absence of surprise bombings) – indeed, one analysis notes rational restraint by nuclear leaders and institutions (including the IAEA framework) has prevented a large nuclear war ([www.un.org](https://www.un.org/en/chronicle/article/next-steps-universal-nuclear-disarmament#:~:text=used,words%2C%20deterrence%20worked%2C%20but%20we)).  However it has also had failures: it failed to detect some secret reactors (Iraq in 1991 was found after Gulf War; North Korea expelled inspectors in 1994).  It has “caught” cheating on occasion (Iran, Syria) largely through intelligence-sharing.  Overall, the IAEA’s pattern is to quietly build a database of nuclear materials and to escalate only when serious evidence emerges.  In an existential-risk forecast, one might expect the IAEA to continue advocating for stronger safeguards (additional protocols) and to gently pressure states on disarmament promises, but it cannot stop a superpower that decides to test or field new nukes.  

## Paris Climate Agreement  
- **Institutional approach/character:** The Paris Agreement is a multilateral treaty (under the UNFCCC) agreed in 2015 by nearly every country.  Its approach is bottom-up and voluntary: each country sets its own “Nationally Determined Contribution” (NDC) for emissions cuts rather than having binding targets imposed from above.  In character it is flexible and non-punitive: it encourages peer pressure and periodic reviews, but it lacks enforcement mechanisms.  The Paris regime is intended to foster recursion – every 5 years countries must update or ratchet up their pledges.  
- **Typical approach to tasks:** Paris’s typical mechanism is the global stocktake and conference of parties (COP).  It relies on transparency (countries report emissions) and diplomacy (joint statements, technology sharing).  It does not involve a formal secretariat like the IPCC or WHO; instead, the UNFCCC parties themselves manage it.  In practical terms, Paris works by having countries announce higher ambition if others do (the “ratchet” mechanism).  During COP meetings it creates forums for high-level talks.  Unlike NPT, Paris is not monitored by inspectors; its “compliance” is moral and political.  
- **Relationships with other entities:** Paris is closely tied to the UN (it is a UN treaty) and to IPCC science (its targets were set with IPCC’s 1.5°C goal in mind).  All major emitters (US, China, EU, India, Russia) are parties (except temporarily the US, which under earlier Trump had withdrawn and would rejoin under another admin).  Because Paris invokes global solidarity, it is often invoked by governments or NGOs when forecasting climate outcomes.  It also indirectly affects private tech: Elon Musk (Tesla) and Bill Gates (climate philanthropy) both reference Paris goals in arguing for innovation.  On the health side, WHO discussions on climate-related disease also link to Paris’s targets.  Paris operates in the same space as technology companies: for instance, commitments to AI for climate or carbon markets (Article 6) tie in.  
- **Current motivations/incentives:** The Paris Agreement’s main incentive for countries is avoiding diplomatic isolation.  Countries are motivated to appear to be “doing their part”; likewise, domestic actors push leaders to join coalitions (e.g. Alliance of Small Island States).  However, without enforcement, the incentive to cheat is high – thus many forecasts worry that aggregate NDCs fall short.  Now (circa 2025) one push is that major partners (EU, China) want to demonstrate leadership; for example, China’s first emissions-reduction pledge in 2025 ([apnews.com](https://apnews.com/article/131761a2089ac8a647ce40a56f1fea44#:~:text=At%20a%20United%20Nations%20climate,The)) partly came in the context of Paris/Brazil COP.  The US under Trump withdrew (viewing Paris as disadvantageous and preferring an “independent” approach ([apnews.com](https://apnews.com/article/788907bb89fe307a964be757313cdfb0#:~:text=On%20January%2020%2C%202025%2C%20shortly,to%20climate%20and%20energy%20policy))), which signaled one country’s incentive is strictly economic, not climate-binding.  Thus, motivations vary: rich democracies often see innovation and reputation benefits from compliance, while others argue development must come first.  
- **Historical patterns of behavior:** Since entering force in 2016, Paris has drawn near-universal signups but only partial implementation.  Historically, initial pledges were weak – just enough to get agreement – and short of 2°C or 1.5°C targets.  The Paris process is iterative: every five years (2020, 2025, etc) countries submit new NDCs; as of 2025 the collective pledges are still insufficient for 1.5°C.  Major powers have wavered: the US left under Trump (2017) and rejoined under Biden (2021) before lapsing out again under a second Trump term ([apnews.com](https://apnews.com/article/788907bb89fe307a964be757313cdfb0#:~:text=On%20January%2020%2C%202025%2C%20shortly,to%20climate%20and%20energy%20policy)).  Other players (EU, China) have ramped up domestic policies.  In forecasting, Paris is likely to remain a symbolic framework – it ensures climate remains a top-tier issue on national agendas, but by itself it does not compel extinction-averse action unless backed by national policies.  Its pattern suggests that it can nudge major emitters to announce targets (as China did in late 2025 ([apnews.com](https://apnews.com/article/131761a2089ac8a647ce40a56f1fea44#:~:text=At%20a%20United%20Nations%20climate,The))) but cannot force those targets to be aggressive enough; like treaties of its kind, its power lies more in norm-setting than in enforcement.  

## Nuclear Non-Proliferation Treaty (NPT)  
- **Institutional approach/character:** The NPT (effective 1970) is a landmark international treaty with three pillars: non-proliferation, disarmament, and peaceful nuclear cooperation.  Its character is legalistic and status-quo–oriented: it essentially legitimizes five nuclear-weapon states (US, Russia, UK, France, China) under a promise of eventual disarmament, in exchange for non-nuclear states foregoing weapons.  It is widely signed (over 190 parties) and is often called the “cornerstone of nuclear stability” ([www.un.org](https://www.un.org/en/chronicle/article/next-steps-universal-nuclear-disarmament#:~:text=match%20at%20L39%20The%20non,The%20NPT%20distinguishes)). The NPT has indefinite extension and periodic review conferences.  Though a treaty (not an “approach” per se), we treat it as an “entity” because it shapes state behavior.  
- **Typical approach to tasks:** Through the NPT, non-nuclear states agree to IAEA safeguards and nuclear cooperation agreements.  The NPT does not itself impose new law; it relied on the IAEA to inspect and on the UN to pressure violations.  Its approach to proliferation has historically been to rely on diplomacy and regime-building (e.g. Nuclear Suppliers Group) rather than force.  On disarmament, it only “requires” an obligation, without timelines – in practice the five nuclear states have largely maintained arsenals (with slow reductions, e.g. US-Russia START treaties in 1990s).  The NPT system typically convenes review conferences every five years to assess progress.  In summary, its approach is to maintain a framework of rules and commitments, but leave the hard enforcement to sovereign decisions or collective actions by the UN.  
- **Relationships with other entities:** The NPT is closely integrated with the IAEA (which carries out compliance checks) and with the UN (the UN General Assembly and Security Council deal with violations).  It binds the US, China, Russia, France, UK, plus India, Pakistan, Israel (non-signers) are referred to as outsiders.  All the listed countries (except India) are NPT members.  The treaty overlaps with the IAEA’s mission, as noted.  The five nuclear powers coordinate through it: for example, the future strategies of the U.S. and Russia (who threatened to resume testing in 2025 ([apnews.com](https://apnews.com/article/ab9a80d523bfb6cc3591b0decfb7527d#:~:text=In%20December%202025%2C%20tensions%20over,has%20established%20a%20strong%20global))) play out within the NPT dialogue context.  It also conceptually intersects with other existential-risk actors: for instance, AI researchers in FHI or CSER note that NPT’s framework has held so far in preventing world nuclear war ([www.un.org](https://www.un.org/en/chronicle/article/next-steps-universal-nuclear-disarmament#:~:text=used,words%2C%20deterrence%20worked%2C%20but%20we)).  
- **Current motivations/incentives:** The current incentive structure is strained.  Non-nuclear states want progress on disarmament and feel aggrieved by the perceived “nuclear have-nots” status, which incentivizes them to push for new measures (e.g. a UN-backed weapons ban treaty outside the NPT, which some call a duplication).  Nuclear states often cite security (North Korea, Iran) as excuses to hold onto arsenals or modernize them.  For example, Trump’s US administration, citing others, justified resuming nuclear tests ([apnews.com](https://apnews.com/article/ab9a80d523bfb6cc3591b0decfb7527d#:~:text=In%20December%202025%2C%20tensions%20over,has%20established%20a%20strong%20global)) ([apnews.com](https://apnews.com/article/2a579544cadd0e70d8eff1c4ea285756#:~:text=Solomon%20defended%20President%20Donald%20Trump%27s,equal)), which undermines non-proliferation norms.  Meanwhile, global stability incentives still favor no-one-starts-first: the promise of deterrence working discourages overt proliferation.  Thus the NPT remains as much a political theater as a real check – its main motivation is preserving international order and avoiding nuclear war, but states are often driven by their perceived national interest (which may conflict with disarmament).  
- **Historical patterns of behavior:** Historically, the NPT has largely succeeded in keeping proliferation limited: no surprising new nuclear powers emerged beyond those known (barring DPRK’s eventual exit and bomb).  It’s been called “virtually the only effective global arms control” (because deterrence also held).  The five nuclear states have, however, frozen disarmament (no meaningful cuts beyond initial START-era reductions), which has been a source of gridlock.  Sometimes, diverting from the NPT, countries have developed nukes outside it (North Korea withdrew; India and Pakistan never joined).  Review conference outcomes often show widening divides (non-nuclear vs nuclear states).  In a forecaster’s view, the NPT will probably continue as the nominal framework (many actions still reference it) but its pattern suggests incrementalism at best: it will not prevent a determined state from building a bomb (we’ve seen cases when politicians decide security overrides treaties), but it does maintain a broad status quo and the threat of sanctions for violators.  

## OpenAI (AI Research Company)  
- **Personality/character:** OpenAI is a U.S.-based AI lab and company founded with a professed mission to ensure artificial general intelligence (AGI) benefits humanity.  Its leadership (Sam Altman and team) publicly voice concern about AI safety, though it is a competitive tech enterprise.  The culture is a mix of Silicon Valley innovation ethos and a modicum of safety consciousness (e.g. early on promoting system of ethics).  It went from non-profit to a “capped-profit” model with Microsoft backing, reflecting both idealistic and commercial impulses.  In publications and statements, it often emphasizes “responsible” development, but as a company it also prioritizes rapid advancement.  
- **Typical approach to tasks:** In practice, OpenAI moves fast to develop and release powerful models (GPT series, Codex, DALL-E), then studies and mitigates their risks.  It often publishes research papers or blog posts on both capabilities and safety (e.g. “AI safety” papers on misuse or alignment).  It engages with regulators and academia to some extent, but also tightly guards cutting-edge techniques.  The company frequently holds “red teams” or issues internal “code red” alerts (as Sam Altman disclosed, for intense competition) to manage development pressures ([www.axios.com](https://www.axios.com/2025/12/03/ai-risks-agi-anthropic-google-openai#:~:text=general%20intelligence%20,safety%20in%20the%20AI%20sector)).  According to a 2025 report, OpenAI does relatively well on risk assessment and information-sharing among AI firms ([www.axios.com](https://www.axios.com/2025/12/03/ai-risks-agi-anthropic-google-openai#:~:text=general%20intelligence%20,safety%20in%20the%20AI%20sector)), though critics say the industry overall underinvests in true insulation against existential threats.  
- **Relationships with other entities:** OpenAI’s main relationships are with its tech partners (Microsoft) and with other AI labs (DeepMind, Anthropic).  It was founded partly by Elon Musk (who later departed) and still has informal ties to some EA-aligned thinkers.  In policy terms, OpenAI has engaged with government (e.g. testifying to Congress on AI safety) and collaborates with universities at times on research.  It has no direct role with UN bodies or climate groups, but its products intersect with climate (e.g. AI tools to optimize energy usage).  With global actors, OpenAI engages with EU regulators (e.g. consultation on the EU AI Act) and is suspected to abide by US export rules.  Overall, it’s a private actor but seen as a public good (having lofty mission statements) – this gives it access to futurists (FHI, CSER) who it sometimes consults.  
- **Current motivations/incentives:** OpenAI’s incentives are mixed: mission “beneficial AGI” vs being a market leader.  It clearly feels pressure to outpace competitors (Google, Chinese labs), which can de-prioritize safety.  Publicly, its leaders say they want careful long-term planning, but its actions (rapid model releases, “code red” competition mode ([www.axios.com](https://www.axios.com/2025/12/03/ai-risks-agi-anthropic-google-openai#:~:text=general%20intelligence%20,safety%20in%20the%20AI%20sector))) show profit and market share are strong drivers.  It receives funding (from Microsoft, investors), so growth and results matter.  As AI scrutiny rises, OpenAI also has an incentive to appear responsible: thus it issues high-profile risk statements and participates in AI safety forums.  The tension is visible: a safety index noted it has policies, but industry-wide measures still fall short ([www.axios.com](https://www.axios.com/2025/12/03/ai-risks-agi-anthropic-google-openai#:~:text=general%20intelligence%20,safety%20in%20the%20AI%20sector)).  So OpenAI will likely continue to push frontier capabilities (since that’s its raison d’etre), but it may also conduct more safety research and lobbying to avoid restrictions and to shape governance in its favor.  
- **Historical patterns of behavior:** Historically, OpenAI combined transparency with selectivity.  In early years it open-sourced code and frameworks; more recently it has restricted releases (GPT-3, GPT-4 were gated).  Its pattern is to generate excitement with demos (e.g. GPT-3 writing, DALL·E images) and then negotiate usage terms.  Founders like Elon Musk left due to mission drift, but public messaging often still echoes existential concerns (Musk and others have repeatedly warned of AI risk, even as OpenAI profits from the tech).  It has at times worked with safety researchers (e.g. OpenAI’s alignment team) but also under pressure to commercialize.  In forecasting, the key is that OpenAI is likely to keep accelerating AI capability – it even publicly acknowledges AGI could be near (Hassabis says by 2030 ([www.axios.com](https://www.axios.com/2025/12/05/ai-hassabis-agi-risks-pdoom#:~:text=warned%20that%20some%20dangerous%20uses,interview%20with%20Axios%27%20Mike%20Allen)), and Altman similarly hints) – while rhetorically valuing safety.  Expect it to continue making breakthroughs (and drawing regulators’ attention) and to occasionally signal alarm (as in late-2025 warnings of “catastrophic outcomes” or declaring “code red” when rivals advance ([www.axios.com](https://www.axios.com/2025/12/03/ai-risks-agi-anthropic-google-openai#:~:text=general%20intelligence%20,safety%20in%20the%20AI%20sector))), but also to hedge its bets by shaping the narrative (investing in oversight lag and communications).  

## Google DeepMind (AI Research Lab)  
- **Personality/character:** DeepMind, now a subsidiary of Alphabet (Google), is a research lab focused on AI breakthroughs.  It is known for a scientific culture and high technical skill, led by CEO Demis Hassabis (neuroscientist background).  DeepMind’s public image is less bombastic than Musk’s or OpenAI’s; it exudes confidence from achievements (AlphaGo, AlphaFold) and has recently become more vocal about risks.  Its orientation is to root AI in fundamental research, with marketed interest (some of its tech feeds into Google, but it operates semi-autonomously).  It has a modest, geeky persona, emphasizing “solving intelligence”.  
- **Typical approach to tasks:** DeepMind typically publishes in academic venues and at conferences, often releasing detailed papers.  It collaborates with academia (it began in London), and now works within Google on products like Gemini language models.  When it comes to safety, DeepMind established an Ethics & Society team and has run internal workshops and competitions on alignment.  Its approach is long-horizon research combined with immediate practical demos (e.g. improving Google’s services).  It also engages in policy: DeepMind researchers attend regulatory panels and meetings, although Google’s corporate stance ultimately guides big decisions.  
- **Relationships with other entities:** Naturally, DeepMind is closely tied to Google (which it was acquired by in 2014).  It collaborates loosely with OpenAI (there is a mutual understanding of shared goals, though they compete for talent).  Prime figures like Hassabis have participated alongside Musk and Gates on risk panels (e.g. AGI summits).  DeepMind has a direct link to policy-makers; for example, Hassabis has spoken at AI summits about governance.  It interacts with research institutes (it funds some FHI/CSER projects), and has partnerships with the healthcare sector and London NHS, but not with environmental groups.  Unlike OpenAI, DeepMind has fewer formal ties with governments but more with academic networks.  It contributes to IPCC indirectly by enabling big climate models on Google Cloud.  
- **Current motivations/incentives:** DeepMind is motivated by scientific achievement and by Google’s commercial interest (improving products).  Hassabis has publicly expressed concern about missing an obvious AI safety issue – even calling some risks “already real” such as AI-driven cyberattacks ([www.axios.com](https://www.axios.com/2025/12/05/ai-hassabis-agi-risks-pdoom#:~:text=warned%20that%20some%20dangerous%20uses,interview%20with%20Axios%27%20Mike%20Allen)).  Internally, DeepMind must balance pet projects (the “Longest Turn”), safety research, and corporate directives from Google.  There is an incentive to avoid reputational risk; DeepMind wants to be seen as a responsible leader, so it often publishes cautionary statements about AGI timelines (e.g. forecasting human-level AI by 2030 at a 145-page research paper) and invests in ethics teams.  At the same time, it must not lag behind commercial rivals (especially Chinese firms and OpenAI), so it is racing on capability.  A tension is visible: while details are secret, DeepMind’s public posture is dual – enthusiastic about potential but warning about existential threats (it recently described such threats as "not your job" but yet "p(doom)" discourse ([www.axios.com](https://www.axios.com/2025/12/05/ai-hassabis-agi-risks-pdoom#:~:text=warned%20that%20some%20dangerous%20uses,interview%20with%20Axios%27%20Mike%20Allen))).  
- **Historical patterns of behavior:** DeepMind gained acclaim by solving complex AI challenges (AlphaGo beat the human champ, Alphafold cracked protein folding).  Historically, it kept a low profile on risk, focusing on achievements.  More recently (circa 2024–2025), its CEO has become more vocal on risks – for example warning at Axios Summit of “catastrophic” outcomes if AI is misused ([www.axios.com](https://www.axios.com/2025/12/05/ai-hassabis-agi-risks-pdoom#:~:text=warned%20that%20some%20dangerous%20uses,interview%20with%20Axios%27%20Mike%20Allen)).  DeepMind’s pattern is pragmatic: when it launched the Gemini model in 2024, it also acknowledged safety risks; it publishes many papers but guards core IP to maintain Google advantage.  Going forward, expect DeepMind to continue pushing AI frontiers (building more powerful models) while increasingly framing this in terms of societal impact.  Its forecasts about AGI are taken seriously (Hassabis’s prediction by 2030 is noted by others) and its approach suggests a measured path – likely to collaborate on international safety standards (e.g. attending summits with EU and US officials), while ensuring Google stays ahead technologically.  

## Elon Musk (Tech Entrepreneur)  
- **Personality/character:** Elon Musk is a high-profile entrepreneur known for ambitious, provocative, and often contrarian stances.  He is visionary in space (SpaceX), automotive (Tesla), and transport (Hyperloop) but also hot-headed on social media.  Musk has a proclaimed libertarian streak, skeptical of established norms.  He is famous for public warnings about AI (“vastly more dangerous than nukes,” he’s said) and is known for contrarian political statements.  His style is passionate and risk-taking – he bets big on moonshot ideas (colonizing Mars, renewable revolution).  
- **Typical approach to tasks:** Musk typically moves decisively on projects when he sees them as vital.  With AI, he initially co-founded OpenAI for safety but later left, frustrated by its direction.  More recently he started xAI to have more control.  On climate, he aggressively expanded electric vehicles and batteries.  In messaging, Musk uses high-profile speeches and tweets; he often lobbies directly (e.g. to U.S. Congress or regulators).  He can shift roles: sometimes cooperating with experts (he funded labs and events on AI risk), other times entangled in culture wars (tweet debates on lockdowns, politics).  His approach is to dramatize issues to spur action – for instance, he’s one of the loudest voices calling for AI regulation, often labeling it an “existential threat.”  
- **Relationships with other entities:** Musk has complex ties: he was an early OpenAI backer but clashed with Sam Altman, leading to his departure.  He coordinates with NASA (SpaceX contracts) and has ties with Pentagon (Starlink deployment).  On AI governance, he’s been in contact with political leaders and some EU officials.  He did donate to organizations concerned with nuclear disarmament (e.g. he’s reportedly funded conversations about preventing global war).  With Bill Gates, Musk has had public disagreements (climate narrative).  He sits outside formal entities like UN but his companies (SpaceX, Tesla) indirectly serve climate goals.  Among the entities listed, he most directly interfaces with international risk forums (e.g. open letters to UN on Ebola in 2020, known exchanges on AI regulations).  
- **Current motivations/incentives:** Musk’s primary motivations include securing humanity’s future (colonizing Mars to avoid extinction by Earth catastrophe, safe AI so it doesn’t kill us).  His incentives are a combination of idealism (long-term survival) and business (his companies grow if new tech solutions are needed).  Currently, he is building a fully autonomous AI (xAI) while screaming caution – his incentive there might be control over AI’s direction.  Politically, he favors deregulation (he clashed with some state lockdowns and mail controls).  He has a stake in shaping public view: by sounding alarm on AI, he humanizes tech progress as risky, pressing others to act (and potentially legitimizing his own projects).  
- **Historical patterns of behavior:** Musk has repeatedly foretold doom if action isn’t taken.  He’s predicted AI killing “all of humanity” and advocated “neural laces” to keep up with machines.  On climate, he pushed from one extreme (selling solar city projects and EVs) to disputes (for example, he once downplayed global warming worries as election eruptions).  He takes an almost gambler’s view on existential threats: he invests in solutions (SpaceX, renewable energy) while publicly fixating on potential disaster.  His pattern is often to start by sounding alarms, then pivot to offering a solution.  As a forecaster, one would view Musk as someone likely to keep pushing radical mitigation (likes of Mars or AI-safeguards) if he stays influential, or to stir public debate even if others find him extreme.  

## Bill Gates (Technologist and Philanthropist)  
- **Personality/character:** Bill Gates is a tech entrepreneur turned philanthropist, characteristically analytical, data-driven and pragmatic.  He often speaks in policy memos or interviews about global challenges, grounded in a problem-solving framework.  He is perennially optimistic about technological solutions but realistic about timelines.  Gates is not polemical like Musk; his style is quietly persuasive, expressed through the Bill & Melinda Gates Foundation’s work and through well-publicized writings (blogs, books).  
- **Typical approach to tasks:** Gates tackles problems by funding research, convening experts, and promoting innovation.  On global health, his approach has been to invest in vaccines and healthcare infrastructure (pushed vaccine distribution in Africa).  On climate, Gates authored a memo in 2025 reframing how we fight warming: he suggested focusing on human suffering and resilience (malaria, nutrition) rather than only cutting emissions ([apnews.com](https://apnews.com/article/4108f76e746d1e3e13845f33b8ae7007#:~:text=argues%20that%20innovation%20in%20clean,related%20challenges)).  He argues for innovation – cleaner energy technology, carbon removal – asserting those are key levers.  He typically publishes strategy reports rather than mobilizing mass movements.  In AI, Gates is cautious but optimistic that aligned development can cure diseases (he’s unlike Musk in not warning of extinction, but he does acknowledge significant risk).  
- **Relationships with other entities:** Gates is closely linked to the WHO and global health institutions (the WHO Foundation partnership, GAVI vaccine alliance).  He sits on or funds various advisory boards for climate and energy research (TerraPower nuclear, Breakthrough Energy).  He interacts with UN and IPCC indirectly by fueling debates (his climate memos are aimed at shaping COP agendas).  He networks with tech and AA researchers (he has met with FHI and other risk analysts).  Politically, he advises governments quietly; he had some association with the now-controversial COVID pre-event, but he generally works behind the scenes.  Gates’s climate stance sometimes contrasts with progressive activists; his 2025 memo ([apnews.com](https://apnews.com/article/4108f76e746d1e3e13845f33b8ae7007#:~:text=argues%20that%20innovation%20in%20clean,related%20challenges)) was widely discussed (Le Monde covered it too).  His public persona engages American and global leaders (he has met Xi and incoming US presidents on climate issues).  
- **Current motivations/incentives:** Gates’s motivations are philanthropic: reducing poverty, disease, and climate harm.  He is incentivized to show his strategies work (e.g. increased funding for climate tech).  Given the question context, Gates likely sees climate change as a serious risk but not existential; instead he advocates pragmatic solutions and warns against panic.  His 2025 memo explicitly downplayed “extinction-level” scenarios in favor of realistic steps, reflecting his incentive to encourage sustainable investment rather than alarmism ([apnews.com](https://apnews.com/article/4108f76e746d1e3e13845f33b8ae7007#:~:text=argues%20that%20innovation%20in%20clean,related%20challenges)).  His climate viewpoint uses an economic argument (“long-term benefits outweigh costs”).  He is also incentivized by his brand (philanthropy leads to public voice) to be at forefront of forging alliances and funding research, for example, he is known to fund AI safety research and global health readiness (CEPI for vaccines, etc.).  
- **Historical patterns of behavior:** Gates has historically focused on “low-hanging” wins: eradicating smallpox, cracking malaria with GM mosquitoes, etc.  On pandemics, he famously warned in 2015 that the world was unprepared for a flu-like pandemic (Ted Talk).  On climate, he’s advocated for breakthroughs (carbon capture, advanced nuclear) and framed climate policy as part of development.  Unlike more activist figures, he rarely employs fear rhetoric; instead he emphasizes facts, funding science, and building consensus for tech solutions.  In forecasts, one would expect Gates to continue promoting incremental improvements: funding research in climate, biosecurity and AI, urging global leaders to “eventually” solve these issues through innovation (with a tendency to sidestep apocalyptic framing).  

## Future of Humanity Institute (FHI, Oxford University)  
- **Approach/character:** FHI is an academic research center headed by Nick Bostrom, specializing in existential risk and long-term future studies.  Its character is interdisciplinary and analytical, drawing on philosophy, mathematics, and policy research.  It is known for rigorously studying risks like superintelligence, nuclear war, biosecurity, and climate collapse.  FHI’s style is intellectual and Socratic – it convenes thinkers to ask “what could go wrong centuries ahead?” rather than running labs or implementing projects.  
- **Typical approach to tasks:** FHI produces papers, books and policy recommendations on existential threats.  It popularized concepts like “AI alignment” and “longtermism.”  It often holds conferences or workshops with stakeholders (e.g. the Feb 2025 workshop with global policymakers on risk governance ([www.fhi.ox.ac.uk](https://www.fhi.ox.ac.uk/workshop-hosted-on-existential-risk/#:~:text=On%20February%208th%20and%209th%2C,the%20Centre%20for%20Effective%20Altruism))).  FHI researchers quantify risk probabilities, evaluate strategic interventions (e.g. lobbying for AI oversight or nuclear safeguards), and advise governments and foundations.  Unlike UN bodies, FHI’s approach is top-down conceptual – they set long horizons (50–100 years) and ask how current actions alter outcomes.  They do not operate projects themselves, but try to influence others’ research and policy.  
- **Relationships with other entities:** FHI is well-connected in the existential-risk community.  It collaborates with the Centre for Existential Risk (CSER) in Cambridge (they often co-author studies), and is part of the effective altruism network.  It has ties to tech CEOs (Sam Altman has met with Bostrom; Musk once donated to related efforts) and often advises governmental panels (UK and US governments have used FHI expertise on emerging tech).  It intellectually connects with UN or WHO by contributing to advisory committees (e.g. Bostrom attended UN panels on AI, drones).  Its relationships are primarily advisory: they may brief the UN Secretary-General or inform IPCC scenarios about “fat-tail” events.  FHI’s networks include philanthropists like Gates (the foundation funds some AI work) and scientific orgs (it is loosely connected to some IAEA/IAF safety communities via mutual interest in disruption scenarios).  
- **Current motivations/incentives:** As a research institute, FHI’s incentives are academic prestige and impact.  It is motivated by philosophical and evidence-based concern over human extinction as the worst outcome.  Grants and donations (some from tech origin, some from governments) drive which topics they emphasize next; recently AI risk is big, but climate and pandemics remain on their radar.  They have an incentive to get decision-makers to think long-term.  This can mean occasionally sounding alarm (e.g. publishing high probability estimates of “doomsday” under current trends) – indeed, their researchers are sometimes accused of extreme predictions.  But they also aim to be credible: their recent policy workshop was about concrete “5–10 year horizon” objectives ([www.fhi.ox.ac.uk](https://www.fhi.ox.ac.uk/workshop-hosted-on-existential-risk/#:~:text=On%20February%208th%20and%209th%2C,the%20Centre%20for%20Effective%20Altruism)), showing an incentive to translate theory into actionable goals.  
- **Historical patterns of behavior:** FHI has a pattern of foresight combined with caution.  Bostrom’s famous 2003 paper coined “existential risk” and he predicted advanced AI might pose a unique AL extinction threat.  FHI influenced the early conversation on AI ethics and has advocated governance (Casino chance).  In the biotechnology domain, they warned about engineered pandemics and urged vigilance.  Over time, FHI’s stance has been to factor in improbable but catastrophic scenarios (the so-called “fat tails”) and to keep tallying emerging threats.  Historically they have pushed organizations like Cambridge and UK IARPA to fund risk assessment.  In a forecasting lens, FHI can be seen as a voice insisting no risk should be ignored: one could expect FHI to release more reports quantifying how likely an ‘x-risk’ is by 2100 and to press governments for policies accordingly (while being criticized for scaremongering by skeptics).  

## Centre for the Study of Existential Risk (CSER, Cambridge University)  
- **Approach/character:** CSER is an interdisciplinary research center focusing on global catastrophic risks and humanity’s future.  Founded by philosopher Huw Price and astrophysicist Martin Rees, CSER brings together scientists, social scientists, and policy experts.  Its character is collaborative and precautionary: it studies a broad range of threats (new technologies, climate, disaster, governance failure).  Unlike FHI which is more theorist-driven, CSER often emphasizes policy and practical solutions.  
- **Typical approach to tasks:** CSER conducts research projects on topics like AI safety, synthetic biology safety, and nuclear risk.  It organizes workshops with stakeholders (academia, industry, government) to devise mitigation strategies.  For example, CSER might work with AI labs to develop safety guidelines, or with agronomists on food security scenarios.  Its approach is to fill knowledge gaps: e.g. one project is on “Long-term global sustainability,” combining climate models with socio-economic trends.  CSER also communicates risks to policymakers (they have briefed UK Parliament committees on AI and on biotechnology).  In short, CSER tries to connect cutting-edge science of risk with on-the-ground policymaking.  
- **Relationships with other entities:** CSER collaborates with FHI and shares many goals (they often co-author or co-host events).  It networks with tech companies (some researchers consult for Google/DeepMind on AI oversight).  CSER is connected to European research grants (it leverages EU funding for some projects).  It engages with the press and think tanks to publicize its findings (e.g. through popular articles or reports).  On international treaties, a CSER member might be interviewed about how advanced biotech could undermine NPT’s lab provisions, or how climate change could exacerbate conflict.  It has informal ties with WHO experts on bio-risk and climate scientists via joint publications.  Essentially, CSER is an academic node linking the “existential risk” academic community with everyday policy and industry networks.  
- **Current motivations/incentives:** CSER is motivated by the urgency of the issues it studies.  It has an incentive to grow public awareness and influence policy; funding and grants (from UK government, philanthropic sources like Google’s philanthropic arm, etc.) shape its research agenda.  With rising public attention on AI and pandemics, CSER likely focuses on these high-profile risks while still covering others (e.g. climate disruption as a chronic risk) to remain comprehensive.  It is incentivized academically to publish influential papers and secure media coverage (its perspective has been cited in some UN reports).  Since CSER does not implement projects directly, its main goal is shaping discourse – so it will probably continue writing policy papers, crafting risk frameworks, and pushing for governmental attention to long-view issues.  
- **Historical patterns of behavior:** CSER has a pattern of being early-warning spotters.  It has, for instance, studied “black swan” technology threats (like nanotech or cybersecurity catastrophes) before they were mainstream concerns.  Its members have advised years ahead of time on nuclear disarmament and radical AI possibilities.  Generally, CSER is seen as always sounding the alarmed-high-risk perspective, emphasizing worst-case scenarios.  In forecasts, CSER’s output is likely to repeatedly stress that we must be cautious – likely highlighting new studies on failure scenarios (e.g. AI disrupting power grids, failed geoengineering).  They historically push incremental steps (like “global monitoring centers”), so one might expect them to advocate for specific measures (perhaps a global AI oversight agency or an X-risk regulatory body) as part of future-oriented risk governance.  

## United States (Country)  
- **Institutional approach/character:** The U.S. operates as a superpower with grand strategy driven by national interest, market logic, and political polarization.  It has a federal government (executive, legislative branches) whose stance can swing dramatically depending on the administration.  Currently (late 2025), with President Trump in office in this scenario, the U.S. is markedly nationalist and dismissive of multilateral constraints (having re-picked Trump’s policies).  The U.S. security apparatus is large and risk-averse to direct nuclear war, yet rhetoric can be bellicose. Domestically, political divisions mean climate and tech policies are contentious.  
- **Approach to existential threats:** Historically, the U.S. has led in combating global diseases (e.g. promoting WHO initiatives, funding vaccine R&D) and in climate efforts under some administrations (signing climate accords, investing in clean energy).  However, the approach fluctuates: under Trump (first term) it withdrew from Paris and downplayed climate risk, then rejoined under Biden. In this 2025 context, Trump withdrew again on day one ([apnews.com](https://apnews.com/article/788907bb89fe307a964be757313cdfb0#:~:text=On%20January%2020%2C%202025%2C%20shortly,to%20climate%20and%20energy%20policy)), indicating a retreat from climate cooperation. In AI, the U.S. is a leader in innovation (house to OpenAI, Anthropic, etc.) and is also trying to set standards (the National Security Commission on AI, US-EU dialogues). Militarily, the U.S. maintains and modernizes the largest nuclear arsenal and is considering easing test bans (Trump cited others to justify tests ([apnews.com](https://apnews.com/article/ab9a80d523bfb6cc3591b0decfb7527d#:~:text=In%20December%202025%2C%20tensions%20over,has%20established%20a%20strong%20global))). The typical U.S. approach is to favor technological solutions (market-driven innovation) over regulation, except when national security is at stake.  
- **Relationships with other entities:** The U.S. is a founding member of all listed treaties (Paris, NPT), UN agencies (WHO, IAEA), and research universities.  Under the Trump-era scenario: it has pulled out of Paris again ([apnews.com](https://apnews.com/article/788907bb89fe307a964be757313cdfb0#:~:text=On%20January%2020%2C%202025%2C%20shortly,to%20climate%20and%20energy%20policy)) and has strained relations with the WHO (Trump’s earlier comments about “China virus”).  It engages heavily with IPCC data but often disputes it politically.  With Russia and China, it is generally competitive or adversarial; e.g. US diplomats in 2025 explicitly blamed China for violating nuclear test moratoria ([apnews.com](https://apnews.com/article/2a579544cadd0e70d8eff1c4ea285756#:~:text=Solomon%20defended%20President%20Donald%20Trump%27s,equal)).  The U.S. tech sector ties it to companies like OpenAI and DeepMind (the latter through Google), and personalities like Gates are American.  Politically, the U.S. interacts with these entities (grant funding, regulation attempts): for example, in late 2025 Trump’s new administration proposed an order to override state AI safety laws, essentially federalizing AI policy in favor of industry ([www.techradar.com](https://www.techradar.com/pro/security/trump-administration-wants-to-use-federal-power-to-challenge-state-ai-laws#:~:text=The%20Trump%20administration%20is%20proposing,sector%20amid%20fears%20of%20a)).  The U.S.’s relations tell us it is simultaneously a leader and a wild card – its domestic politics often upend cooperation (as shown by the Paris and CTBT swings) yet it remains central in any global solution.  
- **Current motivations/incentives:** The current U.S. leadership (Trump) is motivated by economic primacy and national security.  It sees climate action as an economic drag, so withdraws from binding commitments (as it did with Paris 2025 ([apnews.com](https://apnews.com/article/788907bb89fe307a964be757313cdfb0#:~:text=On%20January%2020%2C%202025%2C%20shortly,to%20climate%20and%20energy%20policy))).  Its incentive on nuclear is deterrence and parity: citing alleged Russian/Chinese tests, it argues for resuming its own tests or upgrades ([apnews.com](https://apnews.com/article/2a579544cadd0e70d8eff1c4ea285756#:~:text=Solomon%20defended%20President%20Donald%20Trump%27s,equal)) ([apnews.com](https://apnews.com/article/ab9a80d523bfb6cc3591b0decfb7527d#:~:text=In%20December%202025%2C%20tensions%20over,has%20established%20a%20strong%20global)).  In AI, the Trump administration’s incentive is to maintain American technological dominance, enough to override California’s cautious safety rules ([www.techradar.com](https://www.techradar.com/pro/security/trump-administration-wants-to-use-federal-power-to-challenge-state-ai-laws#:~:text=The%20Trump%20administration%20is%20proposing,sector%20amid%20fears%20of%20a)).  In short, U.S. policy is currently incentivized to deregulate tech and emphasize independence over international cooperation.  However, public opinion and economic interests (like renewable industries) push back, so internal pressures are mixed.  Foreign relations (allies like EU demand U.S. climate action; adversaries like China increase security threats) also shape incentives, but Trump’s rhetoric tends to frame them as validations of a hard line (e.g. “they are testing? so are we ([apnews.com](https://apnews.com/article/2a579544cadd0e70d8eff1c4ea285756#:~:text=Solomon%20defended%20President%20Donald%20Trump%27s,equal))”).  
- **Historical patterns of behavior:** The U.S. history is that of the world’s foremost tech and military power with a tendency to alternate global engagement and isolationism.  It led the development of nuclear arms and then treaties (START, NPT involvement) but also pulled out of disarmament deals (e.g. withdrawing from Intermediate OR 2019 INF).  On climate, it was a Kyoto holdout, then Paris signatory, then Trump pulled out again.  On bio security, it invested in CDC/NIH after 2001 but floundered with COVID.  Historically, the U.S. acts “pragmatically”: it backs international regimes when they align with economic goals, otherwise it acts unilaterally.  In forecasting, expect U.S. actions to continue to swing: if Trump’s control persists, we will see further dampening of global climate or disarmament efforts (as already seen with nuclear tests threats ([apnews.com](https://apnews.com/article/ab9a80d523bfb6cc3591b0decfb7527d#:~:text=In%20December%202025%2C%20tensions%20over,has%20established%20a%20strong%20global))), while the U.S. tech industry pushes AI forward with minimal federal constraint (as evidenced by moves like preempting state AI laws ([www.techradar.com](https://www.techradar.com/pro/security/trump-administration-wants-to-use-federal-power-to-challenge-state-ai-laws#:~:text=The%20Trump%20administration%20is%20proposing,sector%20amid%20fears%20of%20a))).  The domestic front remains a wild card: a shift to another administration could reverse these trends, but under the current scenario U.S. policies lean toward strengthening military/tech power and deprioritizing collective risk mitigation.  

## China  
- **Institutional approach/character:** China’s government is an authoritarian one-party state led by the Communist Party.  Its personality on global issues is that of pragmatic central planning with long time horizons (five-year plans).  It views national security holistically, and its approach is often to set ambitious goals (on economy or tech) and then achieve them via state support.  It is less bound by political pressures like elections, so it can dictate climate or tech policy top-down.  On the international stage, China acts as a rising power seeking respect and stability; its approach is to offer conditional cooperation (e.g. on climate) while avoiding what it sees as external constraints on its development.  
- **Approach to existential threats:** China is the world’s largest greenhouse-gas emitter (>31% of CO₂) but is taking steps to address this.  Notably, in September 2025 China announced its first-ever emissions reduction target (a 7–10% cut by 2035) and pledged massive renewable expansion ([apnews.com](https://apnews.com/article/131761a2089ac8a647ce40a56f1fea44#:~:text=At%20a%20United%20Nations%20climate,The)).  This marks a shift from its earlier posture of emphasizing growth first.  China still builds coal plants, but it is also the leader in renewable capacity now.  On nuclear, China is expanding both civilian reactors and its nuclear arsenal (seeking parity with the US), and the US accuses China of covert weapons tests ([apnews.com](https://apnews.com/article/2a579544cadd0e70d8eff1c4ea285756#:~:text=Solomon%20defended%20President%20Donald%20Trump%27s,equal)) (which China will deny but evidence suggests it may have low-yield detonations linked to arms development).  On AI, China heavily funds its national labs and companies (ByteDance, Huawei) for leadership; Chinese policy frames AI as critical to future economy but also censors content aggressively.  Generally, China’s approach is to invest heavily in tech that it believes secures its future, while playing by international rules selectively (for climate it cooperates in UN forums, for disarmament it will comply with NPT monitoring but build weapons).  
- **Relationships with other entities:** China is a key UN member (holding veto on SC) and a formal party to Paris and the NPT.  It cooperates with the EU and US on global climate talks, even as it competes economically with them.  For instance, at the 2025 UN climate summit China declared its first emissions-cut pledge alongside other major emitters ([apnews.com](https://apnews.com/article/131761a2089ac8a647ce40a56f1fea44#:~:text=At%20a%20United%20Nations%20climate,The)), positioning itself as a climate leader in light of U.S. retreat (sidelining the US was even noted in the week.com piece).  With Russia, China has a “friends with benefits” relationship: they both veto in the UN, sell military tech to each other (Russia provides missile tech, China provides tech investments), and coordinate on presenting a counter-narrative to Western-led institutions.  On AI, China is considered a peer to be reckoned with; its leading AI lab, Baidu’s Ernie/other, competes at the state level.  Regarding pandemics, China was first hit by COVID-19 and tightly controlled it in 2020–2022, and now is a major vaccine and drug exporter.  It does fund WHO initiatives but sometimes claims sovereignty (blocking outside probes).  Overall, China’s relationships are strategic: it cooperates with all when beneficial (renewables tech with EU, nuclear energy deals with UK, African development with India neighbors) but expects respect and little interference in its internal affairs.  
- **Current motivations/incentives:** China is motivated by economic growth, social stability, and national prestige.  Energy security and environmental quality have become higher priorities as pollution and climate impacts mount; thus, its incentive is to push green technology (it leads world in EVs and solar panel production).  Xi Jinping’s promises (carbon peak by 2030, neutrality by 2060) now guide policy, and that sets incentives for research (e.g. funding carbon capture, nuclear power expansion).  On the international front, China wants to appear responsible so as not to alienate trading partners (e.g. announcing climate targets helps at COP30 in Brazil).  Simultaneously, it wants to protect its strategic advantages – so its incentive on AI and biotech is to gain leadership quickly (we see large state AI investments and programs to become global AI leader by 2030).  In the nuclear realm, China wants enough deterrence, so it expands its arsenal quietly (recent Western reports suggest a significant build-up).  Overall, China’s incentives pressure it to aim for technological superiority while maintaining economic growth; it wants multilateral regimes (like the NPT, WHO) to continue functioning with Chinese influence, and so it works these institutions in its favor (vetoing criticisms, for example).  
- **Historical patterns of behavior:** Historically, China put economic growth over environment; for decades it was the biggest emitter and only later recognized climate concerns.  In recent years, influenced by pollution crises and global climate pressure, it pivoted to invest in renewables (now 40% of world solar capacity) and electric vehicles.  Politically, China tends to sign global treaties but interpret them flexibly – it met its Kyoto targets easily (because they were modest), but only later set stronger Paris NDCs under international pressure.  On nuclear, China joined the NPT in 1992 and has mostly complied (IAEA checks show no diversions), but its recent behavior (e.g. reported clandestine tests) suggests a pattern of stealthily pursuing security while professing peaceful intent.  In AI and tech, China’s pattern is state-driven catch-up (its national AI plan, 2030 leadership goal) and protective censorship.  In sum, China likely to continue pragmatic policy: pushing economic and tech leadership (AI, 5G, biotech) while gradually addressing climate as long as it doesn’t decelerate growth – and in foreign policy, it will be cooperative on existential-risk fronts just enough to gain credit, but not hinder its strategic programs.  

## Russia  
- **Institutional approach/character:** Russia’s current regime (under Vladimir Putin) is an authoritarian state with a debt to Soviet-era military doctrine and an interest in strategic leverage.  It depicts itself as a great power resurgent, skeptical of liberal norms.  Its approach is often transactional: it will engage internationally if it serves national interests, but otherwise pushes vice versa (as with the Ukraine conflict).  In existential risk areas, Russia tends to underplay climate change (it’s heavily reliant on fossil fuels, so it views aggressive climate action as a threat to its economy).  
- **Approach to existential threats:** On nuclear weapons, Russia has one of the world’s largest arsenals.  Recently (2025) it threatened to resume nuclear tests along with the US ([apnews.com](https://apnews.com/article/ab9a80d523bfb6cc3591b0decfb7527d#:~:text=In%20December%202025%2C%20tensions%20over,has%20established%20a%20strong%20global)), showing willingness to upend the test moratorium.  It maintains a strict no-first-use rhetoric publicly but has repeatedly hinted it might not abide by NPT-era disarmament in critical situations.  On climate, Russia modestly acceded to Paris targets but has done little domestically (extending gas pipelines even as alternative energy gains, and warming releasing Arctic minerals).  Plausibly though, Russia has some interest in preventing climate-driven conflicts near its borders.  On AI, Russia lags behind US/China in private tech but invests military applications (e.g. autonomous tanks, cyberweapons).  Concerning pandemics, Russia vaccinates its citizens (Sputnik V export to allies) but often downplays global health coordination.  Overall its approach is opportunistic: exploit global gaps (e.g. energy crisis as citrate), and use tools like nuclear arms as bargaining chips.  
- **Relationships with other entities:** Russia is a UN Security Council member but often uses its veto or abstains to shield allies (e.g. Syria).  It is a signatory of the NPT but simultaneously modernizes its arsenal (it’s jointly planning with China to violate test bans).  Its relationship with China is strategic; the two back each other in U.N. forums and have energy and tech partnerships (e.g. joint pipeline deals).  With the U.S. and NATO, Russia is deeply adversarial; the U.S. is quick to accuse Russia of breaking nuclear norms ([apnews.com](https://apnews.com/article/ab9a80d523bfb6cc3591b0decfb7527d#:~:text=In%20December%202025%2C%20tensions%20over,has%20established%20a%20strong%20global)) ([apnews.com](https://apnews.com/article/2a579544cadd0e70d8eff1c4ea285756#:~:text=Solomon%20defended%20President%20Donald%20Trump%27s,equal)), and that has led to tit-for-tat nuclear extinction rhetoric.  On climate, Russia occasionally shows up at UN talks (e.g. COP meetings) but with minimal domestic action, often playing “advisory” role in energy technology.  Russia has historical ties with India (weapons sales) and engagement with EU on trade (until very recently).  It has a partnership with scientific communities (e.g. joint labs with Europe on environment) though overshadowed by politics.  
- **Current motivations/incentives:** Russia’s littoral motivation is regime survival by providing economic wealth and asserting global relevance.  Fossil fuel revenues incentivize resisting sharp emissions cuts (short-term economic priority).  Regarding existential threats, Russia’s current narrative justifies nuclear readiness as deterrence (accusing others of provocation ([apnews.com](https://apnews.com/article/2a579544cadd0e70d8eff1c4ea285756#:~:text=Solomon%20defended%20President%20Donald%20Trump%27s,equal))).  The incentive now is to regain parity with U.S. on nuclear (after perceiving U.S. and China miss tests, Putin agrees to match them).  In AI, Russia feels incentive to catch up militarily, but not to lead ethically.  On pandemics, interest is borderline (it vaccinates its population quickly, but doesn’t push WHO reforms).  Politically, Russia wants to weaken Western alliances by destabilizing the narrative (for example, promoting conspiracy theories about COVID or climate so as to undermine trust in Western institutions).  In forecasting perspective, current motivations suggest Russia will double down on hard power (nuclear modernization, information warfare) rather than cooperate on existential risk.  
- **Historical patterns of behavior:** Historically, Russia (and the USSR before it) has alternated between treaty participation and unilateral action.  It signed the NPT and CWC, then ignored them when convenient (tested nuclear weapons, invaded neighbors).  In arms control, after the Soviet collapse it reduced stockpiles, but since the 2010s it has rebuilt many of them.  On climate, historically it was skeptical – only now reluctantly acknowledging climate in diplomatic settings.  During COVID, Russia at times spread disinformation while for itself promoting domestic products.  Its pattern is to bristle at being constrained – from withdrawing from the 1987 Intermediate-Range Treaty to launching a full-scale war in 2022.  In light of existential risk, one expects Russia to remain troublemaker: undermining treaties (resuming nuclear tests as threats ([apnews.com](https://apnews.com/article/ab9a80d523bfb6cc3591b0decfb7527d#:~:text=In%20December%202025%2C%20tensions%20over,has%20established%20a%20strong%20global))), fueling cynicism about health or environmental science, and generally behaving unpredictably to gain leverage.  

## European Union (EU)  
- **Institutional approach/character:** The EU is a unique supranational political entity combining 27 member states.  Its institutional character is consensus-based but Federalist in ambition: it passes common regulations on trade, environment, and technology that apply EU-wide.  On global issues, the EU often positions itself as a normative power – championing human rights and climate action.  Its approach is methodical and regulatory: it typically forms expert committees (e.g. on AI ethics) and issues binding directives (like the Green Deal).  The EU values multilateralism and often acts as a bloc in the UN and treaties (it was, for instance, pivotal in brokering the Paris Agreement with China).  
- **Typical approach to existential risks:** The EU tends to lead on climate: it has a Green Deal to reach net-zero by 2050, invests heavily in renewables, and has the Emissions Trading System.  It is pushing stringent policies (like banning single-use plastics) and funding R&D (clean hydrogen, carbon capture).  On nuclear, its member states are split: France relies heavily on nuclear energy, Germany has phased it out, though all abide by EU nuclear safety standards and NPT commitments.  The EU is also active in pandemic response (it coordinated vaccine procurement in 2021).  Regarding AI, the EU has pioneered regulation (the AI Act and the Digital Services Act) that emphasize AI safety, transparency and rights – a cautionary stance compared to U.S. free-market.  Overall, in policy the EU’s approach is high-standards and risk-averse: it imposes the precautionary principle in tech (restricting biotech like gene-editing more than US).  
- **Relationships with other entities:** The EU member states are parties to Paris and NPT as part of the EU’s foreign policy (though each has its own military).  The EU works with the UN (e.g. funding WHO initiatives, contributing to UN climate funds).  With the US, the EU is a close ally on most existential issues but sometimes disagrees (e.g. EU pushes tech regulation more aggressively than Trump’s US or current US deregulating AI).  With China, the EU is economically intertwined but politically wary (it has climate coop announcements with China, but disputes over trade and security).  India is an emerging partner (EU-India Summit, climate tech transfers).  The EU does not deal directly with OpenAI or DeepMind differently than any big market – it mostly engages on antitrust and data privacy (the EU’s GDPR and forthcoming AI Act have global repercussions).  The EU also works with IPCC: in UN climate talks, it often teams up with small island or developing countries to push stronger commitments.  
- **Current motivations/incentives:** The EU is motivated by its internal constituencies (Europeans demand climate action, privacy, and stability) and by the desire to maintain global influence.  Its incentive on climate is to be a model of sustainable economy (the “first climate-neutral continent”), which it hopes will spur global copying.  On AI, its incentives are to protect citizens (through regulation) and to create a European AI industry that doesn’t fall behind.  It has little military incentive (no EU army) but does coordinate defense (PESCO), including protection against WMD proliferation in neighborhood (e.g. training Ukrainians to check Chernobyl-like hazards).  In short, the EU’s incentives push toward international problem-solving; it seeks to remain relevant by addressing risks head-on (e.g. pledging reductions and working with IPCC scientists) while tying policies to economic growth (Green Deal also creates green jobs).  
- **Historical patterns of behavior:** The EU and its predecessors (EEC) have a history of responding to crises with integration and regulation.  After disasters like Chernobyl, it centralized nuclear safety standards (Euratom).  On climate, the EU was early to implement the Kyoto Protocol domestically and drive Paris.  It has a pattern of ambitious lawmaking: for example, its GDPR fueled privacy protection globally, and it is now shaping global AI norms with proposed laws.  Historically, the EU prefers rulebook diplomacy (binding laws) to the big-power dynamics of the UN.  It often acts multilaterally (e.g. leading funding pledges for UN climate finance).  In forecasting, one expects the EU to remain a steady force on existential issues: pushing for ever-tightening environmental targets, exerting moral pressure on others (e.g. condemning Russia’s test threats).  It’s likely to continue supporting WHO and UN initiatives (the EU is a top WHO funder) and to invest in tech solutions while guarding against tech harms.  However, the EU can also be slow (requiring unanimity on key issues), so progress on very fast-moving threats (like AI arms race) might lag behind its rhetoric.  

## India  
- **Institutional approach/character:** India is a large democracy with a mixed-market economy.  Its governance emphasizes growth, development, and non-alignment.  Culturally, it places some emphasis on its emerging global stature and historical non-proliferation stance (Gandhi-era ideals).  It has a federal structure, but strong central leadership (currently PM Modi) that allows ambitious programs.  On international agreements, India often negotiates strongly to ensure its interests; it tends to adopt deals only if they include allowances for development.  
- **Approach to existential threats:** On climate change, India is both proactive and cautious.  It commits to Paris goals but insists on “climate justice” – i.e., developed countries should take the lead and provide finance.  India has massively invested in solar energy (Solar Alliance initiative) and is building nuclear plants to diversify energy.  At the same time, it continues to finance coal plants for baseload power and growth.  On pandemics, India has become a “world’s pharmacy” (mass vaccine production for COVID and other diseases) but was hit hard by COVID waves, which has made it attentive to health system resilience.  For nuclear-warfare risk, India is an outlier: it is not an NPT signatory (it tested nuclear weapons in 1974) but later developed thermonuclear bombs.  Its approach has been deterrence: it maintains a no-first-use pledge but is modernizing its triad.  India has also advanced missile defense and is in a tense rivalry with Pakistan (also nuclear) and a strategic partnership with the US in balancing China.  In the AI and tech space, India has a growing tech industry but is not a global leader (mostly serving as R&D and services hub); however, it has started national AI programs and facial recognition systems.  
- **Relationships with other entities:** India has a complex web of relationships.  It partners with the US on security (QUAD alliance) and climate (worked with US on solar energy).  It has traditionally been aligned with Russia on defense (buying jets and engines) and often coordinates with Russia & China in forums (e.g. SCO).  On climate, India is a crucial member of the G20 and Paris pact (Prime Minister Modi has hosted COP summits).  It cooperates with the EU on tech and climate (India-EU dialogues), and is open to investment from EU in renewables.  It also interacts with UN agencies (WHO) on health issues, with mixed results (it mandated lockdowns but also had enforcement issues).  On existential-risk institutes, some Indian academics work with global think-tanks, but nationally India has few such centers.  India often bridges global north-south divides (for example, stressing equity at UN climate talks).  
- **Current motivations/incentives:** India’s driving incentives are lifting millions out of poverty, securing energy for growth, and being recognized as a major power.  On climate, its incentive is development-first; it has pledged reductions (40% renewables by 2030) but still seeks energy security via coal and nuclear – it argues that forcing steep cuts would harm its growth and poverty alleviation.  At COPs, India often tries to secure financial aid or technology transfer commitments to make its targets more achievable.  On nuclear and security, India is motivated to deter neighbors (Pakistan and sometimes China) – hence it invests in nukes and missile defense.  Its incentive on tech is largely economic: it wants to grow an IT and AI sector for jobs, so it’s supportive of digital infrastructure but wary of overregulating (there is debate over scrapping or strengthening data laws).  On pandemics, India was motivated to ensure domestic vaccine access first, which it largely achieved by manufacturing Sputnik V and others locally.  
- **Historical patterns of behavior:** Historically, India has been cautious about international constraints that might limit development.  It was skeptical of the Kyoto Protocol (saying rich nations should cut first), and negotiated hard on Paris to get financing guarantees.  It did develop nuclear weapons outside NPT, then agreed in 2008 to a US-brokered 123 Agreement allowing civilian nuclear trade despite not joining NPT.  On climate, India has made broad commitments (e.g. to triple renewable capacity by 2030) but progress has been mixed (coal still dominant).  Its technology sector is risk-taking (it adopted digital Aadhaar ID nationwide quite quickly) but regulatory frameworks around AI/biosecurity remain under development.  In forecasts, one expects India to continue a balancing act: willing to participate in global solutions if it gets concessions (money, technology, recognition), while also pursuing an independent growth strategy.  It is unlikely to adopt aggressive climate or disarmament cuts unless its development needs are met; however, as a rising power it also has an interest in a stable world, so it may moderate rhetoric on things like nuclear war (it did not threaten WWIII over Pakistan’s skirmishes, avoiding superpower engagement).  India’s domestic needs will largely drive its stance on existential threats: e.g., vulnerable to climate impacts (drought, monsoons) and dense population diseases, it may push for health and resilience support rather than acute end-of-world catastrophes.


2025-12-21 15:57:35,693 - src.research.llm - INFO - 
[Step 4/5] Searching for recent news...
2025-12-21 15:57:35,694 - src.utils.llm_client - INFO - Calling API LLM with model=openai/o4-mini-deep-research, temperature=0.7
2025-12-21 16:01:27,270 - src.research.llm - INFO - News Summary:
News Summary:

1. **China vastly expands nuclear arsenal amid high tensions** – Dec 18, 2024 – AP News ([apnews.com](https://apnews.com/article/9c1f0e145a250f2b8bd7f6f3dd4b7083#:~:text=A%20recent%20Pentagon%20report%20reveals,force%20capable%20of%20greater%20and))  
   *Summary:*  A U.S. Pentagon report reveals China now has over 600 nuclear warheads and plans to exceed 1,000 by 2030, modernizing its arsenal for “more varied counterstrikes” ([apnews.com](https://apnews.com/article/9c1f0e145a250f2b8bd7f6f3dd4b7083#:~:text=A%20recent%20Pentagon%20report%20reveals,force%20capable%20of%20greater%20and)).  China is also deepening military ties with Russia.  
   *Relevance:*   Growing nuclear stockpiles and alliances raise the risk of nuclear conflict, one of the most extreme existential threats to humanity.

2. **Putin lowers threshold for nuclear use in new doctrine** – Nov 19, 2024 – AP News ([apnews.com](https://apnews.com/article/91f20e0c9b0f9e5eaa3ed97c35789898#:~:text=In%20response%20to%20the%20U,particularly%20if%20backed%20by%20a))  
   *Summary:*  Russia’s president signed an updated nuclear doctrine explicitly permitting a nuclear response not only to nuclear attacks but also to large-scale conventional attacks (especially if backed by other nuclear powers) ([apnews.com](https://apnews.com/article/91f20e0c9b0f9e5eaa3ed97c35789898#:~:text=In%20response%20to%20the%20U,particularly%20if%20backed%20by%20a)).  This broadens when Russia might use nuclear weapons.  
   *Relevance:*  Easing constraints on nuclear use greatly increases the danger of a nuclear war, a key extinction risk factor if deterrence fails.

3. **Doomsday Clock set at record-near midnight as multiple risks rise** – Jan 23, 2024 – Time ([time.com](https://time.com/6565572/doomsday-clock-ukraine-gaza-war-ai/#:~:text=The%20Doomsday%20Clock%20remains%20set,The%20panel)) ([time.com](https://time.com/6565572/doomsday-clock-ukraine-gaza-war-ai/#:~:text=cited%20Russia%E2%80%99s%20withdrawal%20from%20arms,President%20Rachel%20Bronson%20emphasized%20that))  
   *Summary:*  The Bulletin of the Atomic Scientists kept its symbolic “Doomsday Clock” at 90 seconds to midnight – the closest ever – citing concurrent threats: wars (Ukraine, Gaza), escalating nuclear dangers, rapid advances in AI, and severe climate disasters like record 2023 heat ([time.com](https://time.com/6565572/doomsday-clock-ukraine-gaza-war-ai/#:~:text=The%20Doomsday%20Clock%20remains%20set,The%20panel)) ([time.com](https://time.com/6565572/doomsday-clock-ukraine-gaza-war-ai/#:~:text=cited%20Russia%E2%80%99s%20withdrawal%20from%20arms,President%20Rachel%20Bronson%20emphasized%20that)).  The panel warned this is not stable but a call for urgent action.  
   *Relevance:*  This summarizes expert judgment that humanity faces unprecedented simultaneous perils; such a peak risk environment suggests non-negligible extinction chance if trends continue unchecked.

4. **WHO pandemic treaty talks stall, refocuses on preparedness** – May 27, 2024 – AP News ([apnews.com](https://apnews.com/article/2b0387cdd86baef350ecf58d6c407a6a#:~:text=member%20countries%20convened%20with%20renewed,fighting%20technology))  
   *Summary:*  WHO member states failed to agree on a new pandemic treaty by mid-2024, stalling after 2½ years of talks over issues like pathogen data-sharing. The Assembly shifted to amending existing rules (International Health Regulations) to boost early warning, response capabilities, and a formal “pandemic emergency” declaration power ([apnews.com](https://apnews.com/article/2b0387cdd86baef350ecf58d6c407a6a#:~:text=member%20countries%20convened%20with%20renewed,fighting%20technology)). Director-General Tedros stressed this isn’t failure but that preparedness must improve.  
   *Relevance:*  This underscores that global pandemic preparedness remains a major challenge.  With vaccine and response improvements still lagging, the risk of a future pandemic growing into a civilization-threatening event remains.

5. **U.S. leads new international AI safety alliance** – Nov 21, 2024 – Time ([time.com](https://time.com/7178133/international-network-ai-safety-institutes-convening-gina-raimondo-national-security/#:~:text=The%20U,ensure%20equitable%20benefits%20from%20AI))  
   *Summary:*  The U.S., under Commerce Secretary Gina Raimondo, convened a Global Network of AI Safety Institutes (INAISI) with experts from 9 countries and the EU to address “growing risks of advanced AI” ([time.com](https://time.com/7178133/international-network-ai-safety-institutes-convening-gina-raimondo-national-security/#:~:text=The%20U,ensure%20equitable%20benefits%20from%20AI)). The initiative aims for global coordination on AI safety research, risk testing, and equitable development. Key topics included preventing AI-driven misinformation and security threats.  
   *Relevance:*  High-level collaboration acknowledges that unbounded AI progress poses existential risks.  This reflects trend that leading governments and tech groups see advanced AI as a potential global menace requiring collective action.

6. **Global biodiversity protection barely budges while many species decline** – Oct 28, 2024 – AP News ([apnews.com](https://apnews.com/article/370da9d6ce7e1e9f4c1f918f99e2bb1e#:~:text=Two%20reports%20released%20at%20a,Massive)) ([apnews.com](https://apnews.com/article/370da9d6ce7e1e9f4c1f918f99e2bb1e#:~:text=Meanwhile%2C%20the%20International%20Union%20for,island%20species%20being%20the%20most))  
   *Summary:*  Reports from a UN biodiversity summit show only marginal gains in protected lands and waters (just +0.5% since 2020), far short of targets.  Meanwhile, the IUCN finds a “severe decline” in wildlife: ~38% of tree species and 46,337 species overall are now threatened ([apnews.com](https://apnews.com/article/370da9d6ce7e1e9f4c1f918f99e2bb1e#:~:text=Two%20reports%20released%20at%20a,Massive)) ([apnews.com](https://apnews.com/article/370da9d6ce7e1e9f4c1f918f99e2bb1e#:~:text=Meanwhile%2C%20the%20International%20Union%20for,island%20species%20being%20the%20most)).  Trees alone make up over 25% of globally endangered species.  
   *Relevance:*  Rapid loss of species and ecosystems heightens long-term survival risk. A collapsing biosphere can undermine food, climate stability, and human well-being. These news highlight accelerating environmental degradation tied to existential risk.

7. **Study warns climate ‘tipping points’ loom under current policies** – Aug 2, 2024 – Axios ([www.axios.com](https://www.axios.com/2024/08/02/climate-tipping-points-overshoot-study#:~:text=Agreement%E2%80%99s%201,5%C2%B0C))  
   *Summary:*  Researchers in *Nature Communications* report that global policies (leading to ~2–3 °C warming by 2100) exceed the 1.5 °C Paris target and carry a high risk of triggering irreversible “tipping points.” Even with later mitigation, they estimate a ~45% chance of crossing one or more major climate tipping thresholds by 2300 under present commitments ([www.axios.com](https://www.axios.com/2024/08/02/climate-tipping-points-overshoot-study#:~:text=Agreement%E2%80%99s%201,5%C2%B0C)). Every fraction of a degree of warming increases those risks.  
   *Relevance:*  Current trajectory makes catastrophic climate feedbacks (like ice sheet collapse or methane release) much likelier. Such tipping cascades could threaten global food and water supplies, undermining civilization’s survival.

8. **UN report: world on track for ~3.1°C warming with current pledges** – Oct 24, 2024 – AP News ([apnews.com](https://apnews.com/article/832773cebb14b4ea8c8930580537e567#:~:text=A%20new%20United%20Nations%20Environment,enough%20to%20prevent%20severe%20climate)) ([apnews.com](https://apnews.com/article/832773cebb14b4ea8c8930580537e567#:~:text=The%20only%20scenario%20with%20a,cut%20is%20needed%20by))  
   *Summary:*  A UN Environment Programme report finds that without immediate action, the world is heading for ~3.1 °C warming by 2100 (far above the 1.5–2°C goals). Even full implementation of current national commitments would hit ~2.6 °C ([apnews.com](https://apnews.com/article/832773cebb14b4ea8c8930580537e567#:~:text=A%20new%20United%20Nations%20Environment,enough%20to%20prevent%20severe%20climate)). Only a scenario reaching net-zero midcentury gives ~23% chance of ≤1.5°C. It also notes top emitters (the 20 richest countries, 77% of emissions) are largely failing on targets ([apnews.com](https://apnews.com/article/832773cebb14b4ea8c8930580537e567#:~:text=The%20only%20scenario%20with%20a,cut%20is%20needed%20by)).  
   *Relevance:*  This confirms that global climate policies are grossly inadequate. High levels of warming will entail extreme impacts (heat, drought, storms) severely challenging human societies. It implies the climate threat by 2100 could be much greater than intended by policymakers.

9. **Bird-flu virus in U.S. patient shows concerning mutation** – Dec 27, 2024 – AP News ([apnews.com](https://apnews.com/article/a870a8d4d86d3dd95f4c0d5c7e9edee5#:~:text=A%20recent%20CDC%20analysis%20has,to%20the%20virus%20finding%20a)) ([apnews.com](https://apnews.com/article/a870a8d4d86d3dd95f4c0d5c7e9edee5#:~:text=,warning%20that%20future%20influenza%20pandemics))  
   *Summary:*  CDC researchers report that the H5N1 bird flu virus in one Louisiana patient mutated to gain a genetic change potentially improving its binding to human airways ([apnews.com](https://apnews.com/article/a870a8d4d86d3dd95f4c0d5c7e9edee5#:~:text=A%20recent%20CDC%20analysis%20has,to%20the%20virus%20finding%20a)).  Fortunately, no human-to-human transmission was found; the patient’s case was linked to animal exposure ([apnews.com](https://apnews.com/article/a870a8d4d86d3dd95f4c0d5c7e9edee5#:~:text=,warning%20that%20future%20influenza%20pandemics)). Experts warn this mutation “finds a key” but still can’t “open the door” to easy spread. Vigilance for new viral threats remains critical.  
   *Relevance:*   Emerging infectious diseases are a classic existential risk. News of such adaptive mutations — even if not yet causing an outbreak — underscores that zoonotic pathogens can evolve unpredictably, keeping global pandemic risk high.

Key Trends Identified:

- **Converging Catastrophic Risks:**  Many reports highlight multiple existential threats rising simultaneously – nuclear conflict (arms races and doctrinal shifts), runaway climate change (warming well beyond safe limits), major pandemics, and advanced AI. The Doomsday Clock’s record closeness to midnight ([time.com](https://time.com/6565572/doomsday-clock-ukraine-gaza-war-ai/#:~:text=The%20Doomsday%20Clock%20remains%20set,The%20panel)) symbolizes this convergence.

- **Insufficient Global Mitigation:**  Current policies lag far behind what’s needed.  Climate pledges still point to ~3°C warming ([apnews.com](https://apnews.com/article/832773cebb14b4ea8c8930580537e567#:~:text=A%20new%20United%20Nations%20Environment,enough%20to%20prevent%20severe%20climate)) and likely cross tipping points ([www.axios.com](https://www.axios.com/2024/08/02/climate-tipping-points-overshoot-study#:~:text=Agreement%E2%80%99s%201,5%C2%B0C)).  Pandemic agreements stalled ([apnews.com](https://apnews.com/article/2b0387cdd86baef350ecf58d6c407a6a#:~:text=member%20countries%20convened%20with%20renewed,fighting%20technology)) and vaccine infrastructures remain uneven.  Overarching trend: fragmented action and missed targets are making dire outcomes more probable.

- **Escalating Nuclear Dangers:**  Major powers (China with growing arsenals ([apnews.com](https://apnews.com/article/9c1f0e145a250f2b8bd7f6f3dd4b7083#:~:text=A%20recent%20Pentagon%20report%20reveals,force%20capable%20of%20greater%20and)), Russia lowering use-threshold ([apnews.com](https://apnews.com/article/91f20e0c9b0f9e5eaa3ed97c35789898#:~:text=In%20response%20to%20the%20U,particularly%20if%20backed%20by%20a))) are intensifying nuclear postures, eroding arms-control norms. This trend sharply increases the chance of conflict spiraling out of control.

- **Emerging Tech Risks and Coordination:**  AI has moved from niche concern to top-tier risk on policy agendas, as seen by the US-led international AI safety network ([time.com](https://time.com/7178133/international-network-ai-safety-institutes-convening-gina-raimondo-national-security/#:~:text=The%20U,ensure%20equitable%20benefits%20from%20AI)). Similarly, biotechnology (e.g. highly transmissible viruses or gene editing) is under watch. The trend is growing recognition among governments and experts that new technologies can become existential threats if unchecked.

- **Deteriorating Environmental Foundations:**  Biodiversity loss (forest, species decline) and climate deterioration continue apace ([apnews.com](https://apnews.com/article/370da9d6ce7e1e9f4c1f918f99e2bb1e#:~:text=Meanwhile%2C%20the%20International%20Union%20for,island%20species%20being%20the%20most)) ([apnews.com](https://apnews.com/article/832773cebb14b4ea8c8930580537e567#:~:text=A%20new%20United%20Nations%20Environment,enough%20to%20prevent%20severe%20climate)). This undermines ecosystem services and climate stability, contributing to a trend of environmental fragility that compounds other risks to human survival.


2025-12-21 16:01:27,282 - src.research.llm - INFO - 
[Step 5/5] Generating final comprehensive report...
2025-12-21 16:01:27,284 - src.utils.llm_client - INFO - Calling API LLM with model=openai/o4-mini-deep-research, temperature=0.7
2025-12-21 16:13:24,237 - src.research.llm - INFO - 
======Research Report Start======
2025-12-21 16:13:24,241 - src.research.llm - INFO - # Global Risk Overview  
Humanity now faces multiple overlapping existential threats.  Recent science reports show Earth has already warmed ≈1.3°C (2024), with projected warming of ~2.3–2.8°C by 2100 under current policies ([apnews.com](https://apnews.com/article/123b935413307fcfad96f8f6e1ec8a16#:~:text=The%20report%20underscores%20the%20urgency,track%20for%20a%204%C2%B0C%20rise)).  Surpassing 1.5°C is all but certain, and experts warn this “overshoot” greatly raises the chance of irreversible climate tipping points (e.g. ice-sheet collapse, ecosystem die-off) ([apnews.com](https://apnews.com/article/c387cf773ece4c60cd6039be1ffb70ef#:~:text=Scientists%20warn%20that%20exceeding%20this,Climate%20models%20now%20suggest%20temperatures)) ([apnews.com](https://apnews.com/article/e8a1b2365883be9781a72446302fc421#:~:text=Despite%20optimism%20around%20renewable%20advancements%2C,He)).  At the same time, geopolitical tensions and arms races are intensifying: nuclear arsenals are expanding and some powers are revising their use doctrines. For example, in late 2025 U.S. officials cited alleged Russian and Chinese nuclear-test violations to justify resuming U.S. nuclear testing ([apnews.com](https://apnews.com/article/2a579544cadd0e70d8eff1c4ea285756#:~:text=At%20a%20nuclear%20arms%20control,with%20other%20nuclear%20powers)), and the landmark U.S.–Russia New START treaty will expire in Feb 2026 ([apnews.com](https://apnews.com/article/2a579544cadd0e70d8eff1c4ea285756#:~:text=underscores%20growing%20instability%20in%20nuclear,the%20first%20time%20in%20decades)), potentially leaving no formal limits on thousands of warheads.  Pandemic risk remains salient too: COVID-19 spurred new WHO initiatives (a global pathogen-origin framework and a draft pandemic treaty), but unpredictable zoonotic threats (e.g. recent H5N1 bird-flu mutations) persist.  Advanced AI is now widely recognized as a future hazard; major countries have convened an international AI safety network ([time.com](https://time.com/7178133/international-network-ai-safety-institutes-convening-gina-raimondo-national-security/#:~:text=The%20U,The%20network%2C%20first)) and private labs (OpenAI, DeepMind, etc.) are racing toward superhuman systems while publicly studying their risks.  Finally, environmental foundations (biodiversity, food systems, clean water) are eroding: protected areas have barely grown, while ~38% of tree species (~46,337 species) are now classified as threatened ([apnews.com](https://apnews.com/article/370da9d6ce7e1e9f4c1f918f99e2bb1e#:~:text=Two%20reports%20released%20at%20a,target%2C%20and%20effectiveness%20and%20respect)) ([apnews.com](https://apnews.com/article/370da9d6ce7e1e9f4c1f918f99e2bb1e#:~:text=Meanwhile%2C%20the%20International%20Union%20for,which%20has%20experienced%20population%20declines)).  In sum, authoritative sources (including the Bulletin of the Atomic Scientists) report an “unprecedented” convergence of threats ([time.com](https://time.com/6565572/doomsday-clock-ukraine-gaza-war-ai/#:~:text=The%20Doomsday%20Clock%20remains%20set,The%20panel)), though the overall probability of total human extinction by 2100 is highly uncertain.

## Key Entities and Their Positions  
- **United Nations (UN)**: The UN spearheads global recognition of existential risks via reports and treaties, but can only set norms.  UN leaders have issued urgent warnings (e.g. Guterres said 2024’s record 1.5°C weekly spike means humanity is “losing the fight” on climate ([apnews.com](https://apnews.com/article/e8a1b2365883be9781a72446302fc421#:~:text=Despite%20optimism%20around%20renewable%20advancements%2C,He))).  On climate and biodiversity, the UN emphasizes integrated action; for instance, a 2025 UN Environment Assembly linked climate, pollution and land-loss as a single crisis.  However, the UN’s impact depends on member buy-in, as seen when major states (e.g. the U.S. in Jan 2025) withdrew from the Paris Agreement ([apnews.com](https://apnews.com/article/788907bb89fe307a964be757313cdfb0#:~:text=On%20January%2020%2C%202025%2C%20shortly,Trump%20justified)).  The UN also facilitates arms-control and health frameworks (organizing NPT review conferences, WHO health assemblies, etc.), but has no enforcement power beyond moral suasion.

- **IPCC (UN Climate Panel)**: A scientific consensus body.  It repeatedly updates the climate record (AR6 in 2021–22 etc.) and its findings underlie policy debates. The IPCC is deliberately non-prescriptive and conservative in its consensus; it typically reports likely ranges and key risks with high confidence (e.g. unequivocal human role in warming).  Over time its language has grown more urgent, but low-probability catastrophic scenarios often appear in accompanying studies rather than the main reports.  As one appraisal notes, IPCC draws on thousands of studies to project “pathways” of warming, which currently point far above the 1.5°C target even with pledged cuts ([apnews.com](https://apnews.com/article/123b935413307fcfad96f8f6e1ec8a16#:~:text=The%20report%20underscores%20the%20urgency,track%20for%20a%204%C2%B0C%20rise)). Future IPCC assessments (next ~2026 for Working Group I) will inform the global stocktake of the Paris Agreement, but any policy action still lies with governments.

- **WHO (World Health Organization)**: The UN’s lead on pandemics and global health. It now emphasizes preparedness (after COVID-19 delays). In late 2024, WHO launched a global framework to trace origins of novel pathogens.  Throughout 2024–25 member states negotiated a formal “Pandemic Treaty.”  Reports in 2025 confirm that the WHO assembly unanimously approved a new treaty on prevention/preparedness ([apnews.com](https://apnews.com/article/51ff7eddb83db47b869d2729a5f27a6d#:~:text=At%20the%20annual%20World%20Health,had%20previously%20withdrawn%20from%20WHO)) (focusing on vaccine equity and data sharing), although key countries like the U.S. are not participating.  WHO’s role is mainly to coordinate and advise; it issues guidelines and emergency declarations but relies on national action.  Historically, WHO has had mixed performance (e.g. praised for eradicating smallpox; criticized for slow Ebola/COVID responses).  Going forward, WHO is likely to push for stronger reporting standards and R&D cooperation, but as before it cannot compel sovereigns to comply fully.

- **IAEA (International Atomic Energy Agency)**: The global nuclear watchdog. It inspects civilian nuclear facilities under the NPT to verify no covert weapons programs.  The IAEA also promotes peaceful nuclear energy (e.g. for power and medicine). It reports compliance issues (e.g. Iran, DPRK cases) which shape diplomatic pressure.  The IAEA depends on member states for access; some nuclear powers (US, Russia, China) have historically negotiated limits on inspections in military areas.  Importantly, Russia and the U.S. are discussing symmetric nuclear tests: the US Chargé d’Affaires in 2025 noted “suspicions” of low-yield tests by Russia/China since 2019, prompting talk of equal testing by all parties ([apnews.com](https://apnews.com/article/2a579544cadd0e70d8eff1c4ea285756#:~:text=At%20a%20nuclear%20arms%20control,with%20other%20nuclear%20powers)). The IAEA has no mandate for developed weapons, but it underlies the NPT regime’s verification.

- **Paris Climate Agreement**: A 2015 UNFCCC treaty based on voluntary national pledges. It set a goal of “well below 2°C” (ideally ≤1.5°C) by end of century. Unlike older treaties, Paris has no binding targets or penalties; instead it relies on regular reviews (every 5 years) and “naming and shaming.”  In practice, analysts (UNE P, IPCC) find current NDCs insufficient – projected outcomes remain ~2.3–2.8°C warming without major new policies ([apnews.com](https://apnews.com/article/123b935413307fcfad96f8f6e1ec8a16#:~:text=The%20report%20underscores%20the%20urgency,track%20for%20a%204%C2%B0C%20rise)).  The agreement’s “ratchet mechanism” is slow: national pledges have gradually risen (e.g. China only announced its first-ever emissions-reduction goal in 2025 ([apnews.com](https://apnews.com/article/131761a2089ac8a647ce40a56f1fea44#:~:text=At%20a%20United%20Nations%20climate,The))).  Key developed economies (EU, China, rejoined US) often meet or strengthen targets; as of 2025 the US under Trump’s second term had withdrawn ([apnews.com](https://apnews.com/article/788907bb89fe307a964be757313cdfb0#:~:text=On%20January%2020%2C%202025%2C%20shortly,Trump%20justified)), while China and EU sharpened theirs.  Thus Paris serves mainly as a framework keeping climate change on the agenda; it cannot enforce extinction-avoiding actions on its own without national follow-through.

- **Nuclear Non-Proliferation Treaty (NPT)**: A 1970 multilateral treaty with over 190 parties, which prohibits non-nuclear states from obtaining nukes and commits nuclear states to eventual disarmament. The NPT is supported by IAEA safeguards. It has effectively limited new nuclear states (apart from the exceptions: India, Pakistan, Israel never joined; North Korea withdrew).  Historically it is credited with stabilizing the nuclear order.  However, its disarmament “Article VI” has few enforcement mechanisms – nuclear powers have largely maintained or modernized arsenals rather than disarming. Recent US and Russian nuclear modernization programs suggest a stagnation. For instance, in late 2025 the US began signaling a return to nuclear testing citing others’ actions ([apnews.com](https://apnews.com/article/2a579544cadd0e70d8eff1c4ea285756#:~:text=At%20a%20nuclear%20arms%20control,with%20other%20nuclear%20powers)). The NPT remains the cornerstone of the status quo: diplomats use it as a rallying point, but it offers no guarantee against a state eventually pursuing weapons, as history has shown (e.g. DPRK).

- **Technological Companies & Figures (AI labs, entrepreneurs)**: Several private entities are now prominent in existential-risk discourse.  OpenAI and Google’s DeepMind (with U.S. and UK backing respectively) are pushing AI capabilities rapidly. Both have publicly acknowledged long-term risks (e.g. authors in DeepMind have warned of “catastrophic outcomes” if misused), and they engage with policy-makers on AI safety. For example, leading governments in 2024 formed an International Network of AI Safety Institutes involving major countries and the EU ([time.com](https://time.com/7178133/international-network-ai-safety-institutes-convening-gina-raimondo-national-security/#:~:text=The%20U,The%20network%2C%20first)), indicating that private labs’ concerns are being institutionalized. Individual tech leaders amplify these issues: Elon Musk (co-founder of OpenAI early on) frequently calls advanced AI an “existential threat,” while Bill Gates (Microsoft co-founder) funds AI and climate R&D and frames innovation as humanity’s path forward ([apnews.com](https://apnews.com/article/4108f76e746d1e3e13845f33b8ae7007#:~:text=In%20a%20memo%20released%20ahead,more%20immediate%20and%20impactful%20ways)).  However, these companies and figures also compete commercially; for instance, OpenAI under pressure from investors has accelerated releases (GPT-4, etc.) even as safety teams research alignment. Overall, the tech sector will likely continue driving breakthroughs (and attendant debate) – shaping the long-term narrative of risk versus benefit. 

- **Future of Humanity Institute (FHI) & Centre for the Study of Existential Risk (CSER)**: These academic research centers (Oxford and Cambridge respectively) have pioneered structured study of extinction risks.  FHI (led by Nick Bostrom) and CSER (led by Martin Rees et al.) analyze scenarios (AI, biotech, climate, nuclear, etc.) often emphasizing “fat-tail” events. They publish influential papers and advise governments and foundations. While not decision-makers themselves, they are key opinion-shapers. For example, FHI’s work popularized the term “longtermism” and metrics for risk; CSER has briefed policymakers on nuclear and AI safety. Their tradition is to stress low-probability, high-impact disasters (falling in line with the Bulletin’s alarm) and to urge precautionary governance. As such, forecasters should consider their analyses as expert commentary – albeit with the caveat that such projections involve extreme uncertainties and normative judgments. 

- **United States**: As a superpower, the U.S. plays a central role.  At present (under the 2025–2029 administration), U.S. policy is inward-facing: in Jan 2025 the US again exited the Paris Accord ([apnews.com](https://apnews.com/article/788907bb89fe307a964be757313cdfb0#:~:text=On%20January%2020%2C%202025%2C%20shortly,Trump%20justified)), contrasting with some other industrialized nations. It backed out of some WHO initiatives during COVID and has fluctuated in funding. On nuclear policy, statements by U.S. officials in late 2025 cited other countries’ moves to justify potential nuclear testing ([apnews.com](https://apnews.com/article/2a579544cadd0e70d8eff1c4ea285756#:~:text=At%20a%20nuclear%20arms%20control,with%20other%20nuclear%20powers)). Domestically, the U.S. military and intelligence community prepare for cyber and AI threats, but federal AI regulation is fragmented (the Commerce Dept. led international AI safety efforts ([time.com](https://time.com/7178133/international-network-ai-safety-institutes-convening-gina-raimondo-national-security/#:~:text=The%20U,The%20network%2C%20first))). Silicon Valley and academia continue to lead AI development. The U.S. also invests heavily in climate technologies (battery R&D, CDR) at the national lab and corporate level, even if current federal emissions legislation is modest.  In sum, American actions are pivotal: U.S. leadership or withdrawal (as seen in climate/pandemic roles) can significantly shift global risk dynamics.

- **China**: China is the world’s largest CO₂ emitter (~31% of global total). Historically focused on growth over environment, it in 2025 announced for the first time a quantitative emissions-cut target (7–10% reduction by 2035) ([apnews.com](https://apnews.com/article/131761a2089ac8a647ce40a56f1fea44#:~:text=At%20a%20United%20Nations%20climate,The)), signaling a policy pivot (also committing to vast renewables expansion and electric vehicles). Simultaneously, China is rapidly expanding its nuclear arsenal (reports indicate ~600 warheads in 2025, headed to 1,000 by 2030) and new delivery systems. It participates in UN climate and health forums (it announced its pledge at a UN summit and attends COPs), but it prefers technology/capacity-building approaches. On AI, China has a state-led AI plan aiming for global leadership by 2030, with extensive domestic deployment of surveillance and biotech advancements. Beijing’s foreign policy on existential risks is mixed: it cooperates on climate funding (e.g. Belt & Road renewables), but resists binding constraints. Its behavior suggests a long-term state-driven approach: willing to engage internationally on climate or health if it gains competitive advantage or soft power, while ensuring its security programs (weapons, cyber, biotech) serve national interests.

- **Russia**: Russia is a major nuclear power with an assertive security posture. In its 2024 doctrine, the Kremlin expanded conditions for nuclear use (including against large-scale conventional threats), reflecting a more permissive stance than during the Cold War. It has modernized its strategic and tactical nuclear forces and reportedly resumed nuclear testing undersea and underground as of 2024–25. This has prompted U.S. charges against Russia and questions about global norms. Russia is not a leading player in climate mitigation (its economy depends on fossil fuels and it has not set ambitious emissions targets), though it nominally signed Paris and occasionally cooperates on adaptation. In global health it mostly pursues bilateral deals (e.g. with vaccines) rather than open collaboration. Overall, Russia’s strategy tends to prioritize military/security interests; it may undermine multilateral institutions when it sees advantage (e.g. vetoing UN sanctions or information about bio threats). From a forecasting view, Russia is likely to continue using nuclear deterrence aggressively, adding to general instability.

- **European Union (EU)**: The EU and its member states are collectively inclined toward strong regulatory responses. The EU has set legally binding climate targets (net-zero by 2050) and invested in green tech. It also passed groundbreaking digital laws (e.g. the AI Act) emphasizing precaution and rights, suggesting it will be a restrictive yet influential regime in tech governance. The EU broadly aligns with scientific consensus on climate and health, and remains committed to multilateralism (it is a major donor to WHO and UN climate funds). In the UN context, the EU often bridges developed/developing divides (e.g. offering climate finance to poorer countries). Internally, Europe’s mix of states (some still use nuclear power, others don’t) means nuclear policy is managed at national level, but EU supports non-proliferation broadly. Forecast-wise, the EU is expected to keep pushing strong standards (forcing technologies to include safety by design) and remaining a vocal advocate of collective action on risks.

- **India**: India is emerging as a major player with its own calculus. It refrains from NPT (it never signed, maintaining nuclear weapons since 1998) and has a declared no-first-use policy, but also modernizes its triad for deterrence. On climate, India’s negotiators emphasize “common but differentiated responsibilities”: they argue developed countries should take the lead and provide financial/tech assistance. India has massively expanded solar power and pledged (under Paris) to raise renewables share, but it still builds coal plants for development. Its approach to pandemics has been pragmatic (rapidly scaling up domestic vaccine production and dispensing to neighbors).  On AI and tech, India has a strong IT sector and launched national AI initiatives, mainly viewing AI as an economic opportunity rather than a primary risk. In forecasts, India’s stance will depend on balancing development needs against risk exposures. Given its large population and climate vulnerability (e.g. monsoon changes), it is motivated to demand adaptation support. It is less likely to take extreme forward-leaning positions (for or against) unless tied to those domestic priorities.

## Recent Trends and Developments  
- **Climate policy and targets**: Emissions continue rising globally. UNEP’s 2024 synthesis found that current policies (even with recent increases in pledges) keep 2100 warming around 2.6–2.8°C ([apnews.com](https://apnews.com/article/123b935413307fcfad96f8f6e1ec8a16#:~:text=The%20report%20underscores%20the%20urgency,track%20for%20a%204%C2%B0C%20rise)). Major summits reflect this gap: in Sept 2025 (ahead of COP30 in Brazil), China for the first time announced a quantified emissions cut for 2035 ([apnews.com](https://apnews.com/article/131761a2089ac8a647ce40a56f1fea44#:~:text=At%20a%20United%20Nations%20climate,The)), and over 100 nations pledged fossil-fuel curbs. However, the U.S. under new leadership reversed climate commitments (re-withdrew from Paris on Jan 20, 2025 ([apnews.com](https://apnews.com/article/788907bb89fe307a964be757313cdfb0#:~:text=On%20January%2020%2C%202025%2C%20shortly,Trump%20justified))), illustrating the brittle nature of global cooperation. Meanwhile, research has highlighted that even these targets likely involve a substantial “overshoot” of 1.5°C, with scientists warning of multiple tipping feedbacks (polar ice, permafrost, forests) opening up as temperatures rise ([apnews.com](https://apnews.com/article/c387cf773ece4c60cd6039be1ffb70ef#:~:text=Scientists%20warn%20that%20exceeding%20this,Climate%20models%20now%20suggest%20temperatures)).

- **Nuclear arms and security**: The post-Cold War arms-control architecture has frayed. New START’s looming expiry (Feb 2026) means the largest nuclear powers could operate without formal limits ([apnews.com](https://apnews.com/article/2a579544cadd0e70d8eff1c4ea285756#:~:text=underscores%20growing%20instability%20in%20nuclear,the%20first%20time%20in%20decades)). Russia’s revised doctrine announced in late 2024 explicitly allows nuclear retaliation even after conventional attacks, raising stakes. In 2025, U.S. leaders publicly shrugged at possible nuclear testing, arguing parity with Russia and China ([apnews.com](https://apnews.com/article/2a579544cadd0e70d8eff1c4ea285756#:~:text=At%20a%20nuclear%20arms%20control,with%20other%20nuclear%20powers)). Concurrent regional conflicts (Ukraine war, Middle East clashes) have spurred fears of accidental or intentional escalation. Analysts note that as of 2025 the situation is arguably the most dangerous since the Cold War, a sentiment echoed by the Bulletin’s Doomsday Clock staying at an all-time 90 seconds to midnight ([time.com](https://time.com/6565572/doomsday-clock-ukraine-gaza-war-ai/#:~:text=The%20Doomsday%20Clock%20remains%20set,The%20panel)).

- **Pandemic preparedness**: International pandemic talks have gained momentum after delays. After halting talks in 2024, WHO member states agreed on a pandemic treaty in early 2025 ([apnews.com](https://apnews.com/article/9003e25d3a9dda95277a9f79cbf77a1d#:~:text=WHO%20member%20countries%20have%20finalized,praised%20the%20agreement%20as%20a)) and formally adopted it at the May 2025 Assembly ([apnews.com](https://apnews.com/article/51ff7eddb83db47b869d2729a5f27a6d#:~:text=At%20the%20annual%20World%20Health,had%20previously%20withdrawn%20from%20WHO)). Key elements include commitments to share pathogen data and stockpile essentials, but enforcement mechanisms remain limited. On the ground, research into vaccines and antivirals continues briskly. Nevertheless, surveillance has detected novel risks (e.g. a case of mutated H5N1 in Louisiana was reported in late 2024), reminding observers that a highly transmissible engineered or natural pathogen is a non-trivial threat. In policy, nations are setting up domestic biosecurity agencies, but global integration of such efforts is still in early stages.

- **Artificial intelligence**: AI development accelerated markedly in 2024–2025. New generations of large language and vision models (e.g. OpenAI’s GPT-4, Google’s Gemini) demonstrated capabilities near or beyond human level in many tasks. This drew attention from governments: in Nov 2024 the U.S. convened an International Network of AI Safety Institutes with multiple countries ([time.com](https://time.com/7178133/international-network-ai-safety-institutes-convening-gina-raimondo-national-security/#:~:text=The%20U,The%20network%2C%20first)). The first global AI Summit (2024) and new EU/US draft regulations indicate policy is catching up. Private labs responded with measures like “red-team” exercises and delay of some releases. Overall the trend is bifurcated: capabilities racing ahead, and regulators/ethicists scrambling to establish norms. Key short-term dates include the expected finalization of the EU AI Act (planned 2026) and continued US Congressional activity (e.g. any follow-up to the 2024 AI Executive Order).

- **Biodiversity and ecosystems**: Environmental degradation continues apace. A 2024 UN biodiversity summit reported only minimal increase in protected areas (just +0.5% since 2020; now about 17.6% of land) ([apnews.com](https://apnews.com/article/370da9d6ce7e1e9f4c1f918f99e2bb1e#:~:text=Two%20reports%20released%20at%20a,target%2C%20and%20effectiveness%20and%20respect)). The IUCN’s latest Red List shows critically widespread declines – e.g. over 38% of tree species (46,337 species) are threatened ([apnews.com](https://apnews.com/article/370da9d6ce7e1e9f4c1f918f99e2bb1e#:~:text=Meanwhile%2C%20the%20International%20Union%20for,which%20has%20experienced%20population%20declines)). These trends indicate growing risk of ecosystem collapse, which would in turn undermine food security, health, and climate regulation. Policymakers have started to acknowledge these links, but substantive mitigation (e.g. reducing deforestation, preserving ocean fisheries) remains insufficient. Important environmental milestones ahead include the 2030 biodiversity targets (many of which are currently off-track) and the mandated net-zero dates for major emitters (e.g. 2050 for EU, 2060 for China) which will shape land-use futures.

- **Geopolitical shifts**: Power dynamics are evolving. In 2024–25, strained U.S.–China and U.S.–Russia relations have led to a fragmentation of prior norms (e.g. accusations of space and cyber aggression). Alliances like the Quad (US–India–Japan–Australia) are engaging on security and tech cooperation. Meanwhile, climate diplomacy is also seeing new alignments: the recent cluster of major emitters (China, EU, others) making one-time pledges in 2025 suggests a partial leadership vacuum filled by non-US actors after the U.S. exit from Paris. UN agencies (IAEA, WHO) are under financial strain, pressuring constellations of wealthy states (EU, UK, Japan) to shoulder more of the burden. In sum, the world in 2025 resembles a multipolar stage where international consensus is fragile, a trend likely at least in the medium term.

## Key Dates and Milestones  
- **Jan 20, 2025** – U.S. executive order withdraws from Paris Agreement ([apnews.com](https://apnews.com/article/788907bb89fe307a964be757313cdfb0#:~:text=On%20January%2020%2C%202025%2C%20shortly,Trump%20justified)), resetting U.S. climate policy trajectory.  
- **May 2025** – WHO Assembly finalizes and adopts the new pandemic-preparedness treaty ([apnews.com](https://apnews.com/article/9003e25d3a9dda95277a9f79cbf77a1d#:~:text=WHO%20member%20countries%20have%20finalized,praised%20the%20agreement%20as%20a)) ([apnews.com](https://apnews.com/article/51ff7eddb83db47b869d2729a5f27a6d#:~:text=At%20the%20annual%20World%20Health,had%20previously%20withdrawn%20from%20WHO)) (intended to address failures of the COVID-19 response).  
- **Sept 2025** – UN Climate Summit (Brazil) at which China announces its first quantified emissions-reduction target ([apnews.com](https://apnews.com/article/131761a2089ac8a647ce40a56f1fea44#:~:text=At%20a%20United%20Nations%20climate,The)), and many countries present updated NDCs.  
- **Late 2025** – COP30 (U.N. climate conference in Brazil); countries will present new 2035/2050 plans in a stocktake process. Bill Gates’s memo (Oct 2025) and public debate illustrate the global focus on this event ([apnews.com](https://apnews.com/article/4108f76e746d1e3e13845f33b8ae7007#:~:text=In%20a%20memo%20released%20ahead,more%20immediate%20and%20impactful%20ways)).  
- **Feb 2026** – Expiration of New START treaty ([apnews.com](https://apnews.com/article/2a579544cadd0e70d8eff1c4ea285756#:~:text=underscores%20growing%20instability%20in%20nuclear,the%20first%20time%20in%20decades)) (unless renegotiated); if it lapses, the two largest nuclear forces will have no formal limits for the first time in decades.  
- **2030** – Milestone year for Paris Agreement: countries expected to achieve significant cuts; by then, current pledges aim to cut emissions by ~10% from 2020 levels (still leaving >2°C warming risk). Also the target year for 30% land/ocean protection from the Kunming–Montreal biodiversity deal (currently off track).  

Other upcoming points: mid-century net-zero targets (e.g. EU-2050, China-2060) and major IPCC reports (AR7, projected late 2020s) will also shape the outlook on whether humanity can avoid its own destruction.

## Expert Perspectives and Forecast Context  
Experts and institutions offer varied but serious assessments. The Bulletin of Atomic Scientists’ Doomsday Clock (maintained by veteran researchers) sits at an all-time 90 seconds to midnight ([time.com](https://time.com/6565572/doomsday-clock-ukraine-gaza-war-ai/#:~:text=The%20Doomsday%20Clock%20remains%20set,The%20panel)), symbolizing extreme peril. Its 2024 statement cited concurrent wars, climate extremes, nuclear brinkmanship, and AI advances as reasons. Bill Gates (philanthropist) argues that extreme worst-case scenarios should not overshadow urgent needs: in Oct 2025 he wrote that climate policy should “pivot” to protecting people from present suffering (poverty, disease) while leveraging innovation ([apnews.com](https://apnews.com/article/4108f76e746d1e3e13845f33b8ae7007#:~:text=In%20a%20memo%20released%20ahead,more%20immediate%20and%20impactful%20ways)). In contrast, some longterm risk philosophers would assign higher odds to rare extinction events if nothing changes. For climate specifically, UNEP and IPCC reports emphasize that without sharp new action global warming will far exceed safe limits ([apnews.com](https://apnews.com/article/123b935413307fcfad96f8f6e1ec8a16#:~:text=The%20report%20underscores%20the%20urgency,track%20for%20a%204%C2%B0C%20rise)). Policymakers know this: e.g. in July 2025 Guterres pressed that capital markets and technology must align to keep 1.5°C alive, saying in effect “time is running out” ([apnews.com](https://apnews.com/article/e8a1b2365883be9781a72446302fc421#:~:text=Despite%20optimism%20around%20renewable%20advancements%2C,He)). 

On AI risk, leading thinkers (including those at FHI) warn that superhuman AI could be an existential threat; recent government initiatives (the U.S.-led AI institute network ([time.com](https://time.com/7178133/international-network-ai-safety-institutes-convening-gina-raimondo-national-security/#:~:text=The%20U,The%20network%2C%20first))) were explicitly motivated by concern over such outcomes. Others (especially within industry) counter that AI brings immense benefits and that extinction scenarios are speculative. For nuclear risk, strategists have long argued that established deterrence has “worked” to prevent global war (no nuclear exchange since 1945), but caution that new doctrines and accidents leave some nonzero probability of a launch. On pandemics, epidemiologists vary from optimistic (“we can build better defenses”) to sober (“novel pathogens remain unpredictable”). 

No unified “market expectation” exists for extinction (no stock or insurance market directly prices it). However, some financial reports (e.g. insurance studies) note increasing risk of climate-driven disasters and pandemics on economies. Philanthropic and tech investment trends do reflect existential concerns: e.g. large funds for clean energy and biosecurity. 

In summary, leading analysts and bodies agree that human-caused catastrophes are worsening and must be urgently addressed; they differ on which risk is most imminent and how likely full extinction is. These expert inputs underscore that the probability is far from zero, but also that it is imprecise.

## Uncertainties and Information Gaps  
Forecasting extinction by 2100 is fraught with uncertainty. Key gaps include:  

- **Unknown Extremes**: Climate models increasingly track moderate scenarios, but “fat-tail” outcomes (like rapid ice sheet collapse or runaway feedback loops) are hard to quantify. A recent study in Nature Communications estimated ~45% chance of crossing at least one major climate tipping point by 2300 under current policies, illustrating profound uncertainty in long-term projections ([apnews.com](https://apnews.com/article/c387cf773ece4c60cd6039be1ffb70ef#:~:text=Scientists%20warn%20that%20exceeding%20this,Climate%20models%20now%20suggest%20temperatures)). Similarly, scientists warn that the impacts of losing a quarter of tree species (as now threatened) on global ecosystems are poorly understood ([apnews.com](https://apnews.com/article/370da9d6ce7e1e9f4c1f918f99e2bb1e#:~:text=Meanwhile%2C%20the%20International%20Union%20for,which%20has%20experienced%20population%20declines)), making downstream human impacts unpredictable.  

- **Future Technologies**: The pace and governance of cutting-edge tech (AI, biotech, nanotech) are unpredictable. Small breakthroughs could drastically raise or lower risk. For example, a safe and effective vaccine platform would reduce pandemic danger; conversely, an uncontrolled lab pathogen or unaligned superintelligence could raise it. Contemporary AI labs like OpenAI and DeepMind actively assess risk, but the “alignment problem” remains unsolved; it is unclear whether regulatory or technical solutions will emerge in time.  

- **Political Dynamics**: International cooperation is volatile. Retail pitfalls (e.g. rapid policy reversals, geopolitical crises) are hard to foresee. For instance, U.S. federalism has already created a patchwork on climate and AI (e.g. California AI rules vs. Trump’s federal preemption move announced in late 2025). Future elections or conflicts could similarly upend treaty commitments (as seen with Paris and WHO). The exact trajectory of superpower relations (U.S.-China-Russia interactions) will crucially affect nuclear and climate outcomes, yet political stability cannot be reliably predicted.  

- **Data Shortages**: Many models assume historical patterns continue; they lack data on truly global-scale collapses. There is essentially no precedent for a human extinction event, so risk assessments rely on expert judgment rather than statistical evidence. In some fields (like climate science), data on tipping points or compound disasters is limited. In others (like emerging biotech), secrecy and rapid change leave blind spots.  

- **Long-term Black Swans**: Natural cosmic threats (asteroids, supernovas) have extremely low but nonzero probabilities. Most forecasts ignore these beyond noting they are far less likely this century. However, truly unanticipated risks could emerge (e.g. a novel astrophysical event). Because such events are unforeseeable until they happen, they add deep uncertainty that no current model can capture.  

Given these gaps, all quantitative forecasts of “extinction by 2100” involve high uncertainty. Forecasters should therefore weigh the above evidence — current paths, policy commitments, expert assessments — while remembering that small changes (e.g. massive investment in carbon removal or breakthrough AI alignment guarantees) could dramatically alter outcomes. The question hinges on the interplay of these forces and unlikely “tail” scenarios, not a deterministic prediction. The evidence shows humanity facing heightened danger, but not an inevitable demise by century’s end. 


2025-12-21 16:13:24,292 - src.research.llm - INFO - 
======Research Report End========
2025-12-21 16:13:24,352 - src.utils.llm_client - INFO - Calling Local LLM with model=Qwen/Qwen3-32B (Think), temperature=0.2
2025-12-21 16:13:24,370 - src.utils.llm_client - INFO - Calling Local LLM with model=Qwen/Qwen3-32B (Think), temperature=0.2
2025-12-21 16:13:24,371 - src.utils.llm_client - INFO - Calling Local LLM with model=Qwen/Qwen3-32B (Think), temperature=0.2
2025-12-21 16:13:57,308 - src.utils.llm_client - INFO - Token usage: {'prompt_tokens': 10137, 'total_tokens': 11337, 'completion_tokens': 1200, 'prompt_tokens_details': None}
2025-12-21 16:14:04,541 - src.utils.llm_client - INFO - Token usage: {'prompt_tokens': 10137, 'total_tokens': 11592, 'completion_tokens': 1455, 'prompt_tokens_details': None}
2025-12-21 16:14:06,593 - src.utils.llm_client - INFO - Token usage: {'prompt_tokens': 10137, 'total_tokens': 11665, 'completion_tokens': 1528, 'prompt_tokens_details': None}
2025-12-21 16:14:06,667 - src.forecasting.binary - INFO - Binary forecast complete: 10.00%
2025-12-21 16:14:06,667 - __main__ - INFO - ============================================================
2025-12-21 16:14:06,667 - __main__ - INFO - Forecast Result:
2025-12-21 16:14:06,667 - __main__ - INFO - 0.1
2025-12-21 16:14:06,667 - __main__ - INFO - ============================================================

####################################################################################################
Forecast Summaries
####################################################################################################

-----------------------------------------------
Question: Will humans go extinct before 2100?
URL: https://www.metaculus.com/questions/578/
Forecast: 0.1
Comment:
```
Median Probability: 10.00%

## Rationale 1
Extracted Probability: 10.00%

GPT's Answer: <think>
Okay, let's tackle this question about whether humans will go extinct by 2100. First, I need to understa...
```

2025-12-21 16:14:06,670 - __main__ - INFO - All forecasts completed successfully